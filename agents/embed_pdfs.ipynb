{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86d8163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from typing import Optional, List, Dict\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_mistralai import MistralAIEmbeddings, ChatMistralAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import IpexLLM\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import pdf2doi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff43223",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SYCL_CACHE_PERSISTENT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a354f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "import datauri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441909c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperInfo(TypedDict):\n",
    "    title: Annotated[str, ..., 'Title of the research paper']\n",
    "    author: Annotated[str, ..., 'Authors of the paper in (Name) et al. format']\n",
    "    id: Annotated[str, ..., 'DOI or arXiv ID']\n",
    "    data: Annotated[List[str], ..., 'Data used']\n",
    "    code_link: Annotated[str, 'None provided', 'Link to code (Github, etc)']\n",
    "    packages_used: Annotated[List[str], 'None Provided', 'Packages or libraries used.']\n",
    "    task: Annotated[str, ..., 'Task performed in paper (e.g. flare prediction, CME detection, etc.)']\n",
    "    field: Annotated[str, ...,'What branch of Space Science/Solar Physics e.g. solar flares, CME, solar wind, etc.']\n",
    "    abstract: Annotated[str, ..., 'Summary of abstract']\n",
    "    models: Annotated[List[str], ..., 'Model architecture(s) used e.g. CNN, ResNet, pix2pix, GAN, etc.']\n",
    "    hybrid_model: Annotated[bool, ..., 'Whether hybrid model architectures were used.']\n",
    "    multimodal: Annotated[List[str], 'N/A', 'Type of multimodal models used, if any.']\n",
    "    baselines: Annotated[List[str], 'N/A', 'Baseline models or papers used, along with citations in the format: baseline (author, year).']\n",
    "    preprocessing: Annotated[List[str], ..., 'Preprocessing steps taken']\n",
    "    citations: Annotated[List[str], ..., 'Citations']\n",
    "    approach_used: Annotated[List[str], ..., 'Approach(es) used']\n",
    "    methodology: Annotated[str, ..., 'Summary of methodology']\n",
    "    metrics: Annotated[List[Dict[str, float]], ..., 'Metrics used for evaluation and the scores obtained']\n",
    "    limitations: Annotated[List[str], ..., 'Limitations of the research']\n",
    "    reproducibility: Annotated[float, ..., 'From 0-5, based on the completeness of the method, code and data, how reproducible is the paper?']\n",
    "    strengths: Annotated[str, ..., 'Key strengths']\n",
    "    weaknesses: Annotated[str, ..., 'Key weaknesses']\n",
    "    reuse_potential: Annotated[List[str], 'N/A', 'Notes on potential for reuse (if applicable)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f31e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.environ['MISTRAL_API_KEY'].strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "507d5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df = pd.read_csv('../listup.csv')\n",
    "papers_df['file_name'] = list(map(lambda name: name.split('.pdf')[0].split(' - ')[1], papers_df['file_name']))\n",
    "papers = []\n",
    "\n",
    "for file, content in zip(papers_df['file_name'], papers_df['content']):\n",
    "    papers.append({'file_name': file, 'content': content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2755ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dania\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "W0918 20:51:29.039000 37396 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\dania\\AppData\\Roaming\\Python\\Python311\\site-packages\\intel_extension_for_pytorch\\bin\\intel-ext-pt-gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m llm = \u001b[43mIpexLLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_model_id\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmistralai/Mistral-7B-v0.1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m structured_llm = llm.with_structured_output(PaperInfo)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\langchain_community\\llms\\ipex_llm.py:71\u001b[39m, in \u001b[36mIpexLLM.from_model_id\u001b[39m\u001b[34m(cls, model_id, model_kwargs, tokenizer_id, load_in_4bit, load_in_low_bit, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_model_id\u001b[39m(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     **kwargs: Any,\n\u001b[32m     49\u001b[39m ) -> LLM:\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    Construct object from model_id\u001b[39;00m\n\u001b[32m     52\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m \n\u001b[32m     69\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_bit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mload_in_low_bit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_in_low_bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\langchain_community\\llms\\ipex_llm.py:127\u001b[39m, in \u001b[36mIpexLLM._load_model\u001b[39m\u001b[34m(cls, model_id, tokenizer_id, load_in_4bit, load_in_low_bit, low_bit_model, model_kwargs, kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_model\u001b[39m(\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    125\u001b[39m ) -> Any:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipex_llm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    128\u001b[39m             AutoModel,\n\u001b[32m    129\u001b[39m             AutoModelForCausalLM,\n\u001b[32m    130\u001b[39m         )\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, LlamaTokenizer\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\ipex_llm\\__init__.py:38\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Avoid duplicate import\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ipex_importer.get_ipex_version() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[43mipex_importer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_ipex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Default is true, set to true to auto patching bigdl-llm to ipex_llm.\u001b[39;00m\n\u001b[32m     41\u001b[39m BIGDL_COMPATIBLE_MODE = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mBIGDL_COMPATIBLE_MODE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTrue\u001b[39m\u001b[33m'\u001b[39m).lower() \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\ipex_llm\\utils\\ipex_importer.py:136\u001b[39m, in \u001b[36mIPEXImporter.import_ipex\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mipex\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys.modules \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mintel_extension_for_pytorch\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys.modules:\n\u001b[32m    134\u001b[39m         log4Error.invalidInputError(\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    135\u001b[39m                                     ipex_duplicate_import_error)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdirectly_import_ipex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mself\u001b[39m.ipex_version = ipex.__version__\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Replace builtin import to avoid duplicate ipex import\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dania\\anaconda3\\envs\\space\\Lib\\site-packages\\ipex_llm\\utils\\ipex_importer.py:156\u001b[39m, in \u001b[36mIPEXImporter.directly_import_ipex\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    153\u001b[39m insert_fake_module(\u001b[33m\"\u001b[39m\u001b[33mintel_extension_for_pytorch.llm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfake module\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# import ipex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mintel_extension_for_pytorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipex\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ipex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# Expose ipex to Python builtins\u001b[39;00m\n\u001b[32m    159\u001b[39m     builtins.ipex = ipex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\intel_extension_for_pytorch\\__init__.py:90\u001b[39m\n\u001b[32m     88\u001b[39m                 err = ctypes.WinError(ctypes.get_last_error())\n\u001b[32m     89\u001b[39m                 err.strerror += \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m Error loading \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m or one of its dependencies.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     92\u001b[39m     kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_proxy_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mOSError\u001b[39m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\dania\\AppData\\Roaming\\Python\\Python311\\site-packages\\intel_extension_for_pytorch\\bin\\intel-ext-pt-gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "llm = IpexLLM.from_model_id(\n",
    "    model_id='mistralai/Mistral-7B-v0.1',\n",
    "    model_kwargs={\n",
    "        'temperature': 0\n",
    "    }\n",
    ")\n",
    "structured_llm = llm.with_structured_output(PaperInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = MistralAIEmbeddings(\n",
    "    model='mistral-embed',\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"papers_data\"\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers:\n",
    "    split_paper = text_splitter.split_text(paper['content'])\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name='research_papers'\n",
    "    )\n",
    "\n",
    "    vectorstore.add_texts(split_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f0ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
