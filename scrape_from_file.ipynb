{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c8fa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "from typing import Optional, List, Dict\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import pdf2doi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "28946adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './SSWLAB_논문'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2c46182",
   "metadata": {},
   "outputs": [],
   "source": [
    "sswlab_files = []\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    sswlab_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c94cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperInfo(TypedDict):\n",
    "    title: Annotated[str, ..., 'Title of the research paper']\n",
    "    author: Annotated[str, ..., 'Authors of the paper in (Name) et al. format']\n",
    "    id: Annotated[str, ..., 'DOI or arXiv ID']\n",
    "    data: Annotated[List[str], ..., 'Data used']\n",
    "    code_link: Annotated[str, 'None provided', 'Link to code (Github, etc)']\n",
    "    packages_used: Annotated[List[str], 'None Provided', 'Packages or libraries used.']\n",
    "    task: Annotated[str, ..., 'Task performed in paper (e.g. flare prediction, CME detection, etc.)']\n",
    "    abstract: Annotated[str, ..., 'Summary of abstract']\n",
    "    models: Annotated[List[str], ..., 'Model architecture(s) used e.g. CNN, ResNet, pix2pix, GAN, etc.']\n",
    "    hybrid_model: Annotated[bool, ..., 'Whether hybrid model architectures were used.']\n",
    "    multimodal: Annotated[List[str], 'N/A', 'Type of multimodal models used, if any.']\n",
    "    baselines: Annotated[List[str], 'N/A', 'Baseline models or papers used.']\n",
    "    preprocessing: Annotated[List[str], ..., 'Preprocessing steps taken']\n",
    "    citations: Annotated[List[str], ..., 'Citations']\n",
    "    approach_used: Annotated[List[str], ..., 'Approach(es) used']\n",
    "    methodology: Annotated[str, ..., 'Summary of methodology']\n",
    "    metrics: Annotated[List[Dict[str, str]], ..., 'Metrics used for evaluation and the scores obtained']\n",
    "    limitations: Annotated[List[str], ..., 'Limitations of the research']\n",
    "    reproducibility: Annotated[float, ..., 'From 0-5, based on the completeness of the method, code and data, how reproducible is the paper?']\n",
    "    key_points: Annotated[Dict[str, str], ..., 'Key strengths and weaknesses']\n",
    "    reuse_potential: Annotated[List[str], 'N/A', 'Notes on potential for reuse (if applicable)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f0ffec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model('mistral-large-latest', model_provider='mistralai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d72dd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(PaperInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc213a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "import datauri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4319d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = Mistral(api_key=os.environ['MISTRAL_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5737cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf(file):\n",
    "    pdf = client.files.upload(\n",
    "        file={\n",
    "            'file_name': file,\n",
    "            'content': open(f'./SSWLAB_논문/{file}', 'rb')\n",
    "        },\n",
    "        purpose='ocr'\n",
    "    )\n",
    "\n",
    "    signed_url = client.files.get_signed_url(file_id=pdf.id)\n",
    "    return signed_url.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a824413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(file):\n",
    "    ocr_response = client.ocr.process(\n",
    "        model='mistral-ocr-latest',\n",
    "        document={\n",
    "            'type': 'document_url',\n",
    "            'document_url': upload_pdf(file)\n",
    "        },\n",
    "        include_image_base64=True\n",
    "    )\n",
    "\n",
    "    return ocr_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9552b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = []\n",
    "for file in sswlab_files:\n",
    "    pdf = extract_pdf(file)\n",
    "\n",
    "    content = []\n",
    "    for page in pdf.pages:\n",
    "        content.append(page.markdown)\n",
    "\n",
    "    papers.append({\n",
    "        'file_name': file,\n",
    "        'content': content\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2379bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf in papers:\n",
    "    content = '\\n'.join(pdf['content'])\n",
    "    pdf['content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d975d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', \"Extract information from the following research paper.\"),\n",
    "        ('human', '{paper}')    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2fac7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_llm = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c64548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for paper in papers:\n",
    "    data.append(fin_llm.invoke({'paper': paper['content']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739ccb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Generation of Modern Satellite Data from Galileo Sunspot Drawings in 1612 by Deep Learning',\n",
       "  'author': 'Lee et al.',\n",
       "  'id': '10.3847/1538-4357/abd701',\n",
       "  'data': ['Mount Wilson Observatory (MWO) sunspot drawings (2011-2015)',\n",
       "   'Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI) line-of-sight magnetograms (2011-2015)',\n",
       "   'SDO/Atmospheric Imaging Assembly (AIA) seven wavelength images (94, 131, 171, 193, 211, 304, and 335 Å) (2011-2015)',\n",
       "   'Galileo sunspot drawings (1612 June 2 to July 8)'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['NumPy', 'Keras', 'TensorFlow', 'SunPy'],\n",
       "  'task': 'Generation of modern satellite-like solar magnetograms and EUV images from historical sunspot drawings',\n",
       "  'abstract': \"This study presents a deep learning-based approach to generate modern satellite-like solar magnetograms and EUV images from historical sunspot drawings. The authors use a conditional generative adversarial network (cGAN) model, specifically pix2pix, to translate sunspot drawings from the Mount Wilson Observatory (MWO) into corresponding magnetograms and EUV images from the Solar Dynamics Observatory (SDO). The model is trained on paired data from 2011 to 2015 and evaluated on held-out data from June and December of those years. The results demonstrate that the AI-generated magnetograms and EUV images closely match the bipolar structures and intensities of the original SDO data. The model is then applied to Galileo's sunspot drawings from 1612, producing HMI-like magnetograms and AIA-like EUV images. This approach offers potential for estimating long-term solar EUV irradiance and bridging historical and modern solar data.\",\n",
       "  'models': ['pix2pix (conditional generative adversarial network, cGAN)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Image-to-image translation using deep learning',\n",
       "   'Training on paired sunspot drawings and SDO images',\n",
       "   'Evaluation on held-out data',\n",
       "   'Application to historical Galileo sunspot drawings'],\n",
       "  'methodology': \"The study uses a pix2pix model, a type of conditional GAN, to translate historical sunspot drawings into modern satellite-like images. The model is trained on paired datasets of MWO sunspot drawings and SDO magnetograms/EUV images from 2011 to 2015 (excluding June and December). The training data consists of 1046 pairs, while 204 pairs from June and December are used for evaluation. The model is optimized to generate images that closely resemble the target SDO images in terms of bipolar magnetic structures and EUV brightness. The trained model is then applied to Galileo's sunspot drawings from 1612 to generate HMI-like magnetograms and AIA-like EUV images. The total unsigned magnetic flux (TUMF) and full-disk count rates (CR) are estimated and compared between real and generated images to validate the model's performance.\",\n",
       "  'metrics': ['Mean correlation coefficient (CC)',\n",
       "   'Normalized root mean square error (NRMSE)',\n",
       "   'Total unsigned magnetic flux (TUMF)',\n",
       "   'Full-disk count rates (CR)'],\n",
       "  'limitations': [\"The model does not successfully generate active regions that do not follow Hale's law.\",\n",
       "   'Detailed structures like filaments and coronal holes are not reproduced well in the generated images.',\n",
       "   \"The model's effectiveness is limited to even solar cycles due to the polarity reversal of solar magnetic fields.\",\n",
       "   'Generated EUV intensities and magnetic fluxes may be slightly underestimated compared to real data.',\n",
       "   'The model is dependent on the quality and clarity of historical sunspot drawings.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Innovative approach to bridge historical and modern solar data.',\n",
       "    'High correlation between AI-generated and real magnetograms/EUV images.',\n",
       "    'Potential for estimating long-term solar EUV irradiance.',\n",
       "    \"Successful application to Galileo's sunspot drawings from 1612.\"],\n",
       "   'weaknesses': ['Limited ability to reproduce detailed solar structures like filaments and coronal holes.',\n",
       "    'Model may not generalize well to odd solar cycles without adjustments.',\n",
       "    'Dependence on the quality of historical drawings may limit accuracy.',\n",
       "    'Slight underestimation of EUV intensities and magnetic fluxes in generated images.']},\n",
       "  'reuse_potential': ['The model can be adapted to other historical sunspot datasets to generate modern satellite-like images.',\n",
       "   'Potential for integration with other solar activity studies to enhance long-term solar irradiance estimates.',\n",
       "   'The methodology can be extended to other domains requiring image-to-image translation in astronomy.']},\n",
       " {'title': 'Visual Explanation of a Deep Learning Solar Flare Forecast Model and Its Relationship to Physical Parameters',\n",
       "  'author': 'Yi et al.',\n",
       "  'id': '10.3847/2041-8213/abe94a',\n",
       "  'data': ['Solar and Heliospheric Observatory (SOHO)/Michelson Doppler Imager (MDI) magnetograms',\n",
       "   'Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI) magnetograms',\n",
       "   'Space-weather HMI Active Region Patch (SHARP) parameters',\n",
       "   'Geostationary Operational Environmental Satellite (GOES) X-ray flare data'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['PyTorch', 'NumPy', 'Matplotlib'],\n",
       "  'task': 'Solar flare prediction',\n",
       "  'abstract': \"This study presents a visual explanation of a deep learning-based solar flare forecast model and its relationship to physical parameters of solar active regions (ARs). The model uses full-disk magnetograms from SOHO/MDI and SDO/HMI, SHARP parameters, and GOES X-ray flare data. The Convolutional Neural Network (CNN) model predicts the daily occurrence of C-, M-, and X-class flares. The model is interpreted using guided backpropagation and Gradient-weighted Class Activation Mapping (Grad-CAM), which provide insights into the model's decision-making process. Key findings include the importance of the polarity inversion line (PIL) for flare prediction and the correlation between Grad-CAM values and flare occurrence rates. Additionally, nine SHARP parameters are found to be well correlated with Grad-CAM values.\",\n",
       "  'models': ['Convolutional Neural Network (CNN) with dense connections'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['Event statistics flare forecasting (Wheatland 2005)',\n",
       "   'Deep learning models from Park et al. (2018), Nishizuka et al. (2018), Huang et al. (2018)'],\n",
       "  'approach_used': ['Guided backpropagation',\n",
       "   'Gradient-weighted Class Activation Mapping (Grad-CAM)',\n",
       "   'Visual explanation of CNN models'],\n",
       "  'methodology': \"The study develops a CNN-based deep learning model to predict solar flares using full-disk magnetogram data. The model is trained and tested on chronologically separated datasets from SOHO/MDI and SDO/HMI. Guided backpropagation and Grad-CAM are applied to interpret the model's predictions. The guided backpropagation highlights the polarity inversion line (PIL) as a crucial feature for flare prediction, while Grad-CAM values are used to analyze the relationship between model predictions and physical parameters from SHARP data. The study also compares the model's performance with other flare prediction models using metrics such as Accuracy (ACC), Heidke Skill Score (HSS), Appleman Skill Score (ApSS), and True Skill Statistics (TSS).\",\n",
       "  'metrics': ['Accuracy (ACC)',\n",
       "   'Heidke Skill Score (HSS)',\n",
       "   'Appleman Skill Score (ApSS)',\n",
       "   'True Skill Statistics (TSS)',\n",
       "   'Frequency Bias (FB)',\n",
       "   'Event Rate'],\n",
       "  'limitations': ['The study uses JPG format magnetogram data, which may introduce compression artifacts.',\n",
       "   \"The model's performance is dependent on the quality and resolution of input magnetogram data.\",\n",
       "   \"The attribution methods (guided backpropagation and Grad-CAM) provide insights but may not capture all aspects of the model's decision-making process.\",\n",
       "   'The analysis is limited to specific SHARP parameters and may not generalize to all possible physical parameters of solar active regions.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The study provides a visual explanation of a deep learning model for solar flare prediction, enhancing interpretability.',\n",
       "    'The use of guided backpropagation and Grad-CAM highlights important features such as the polarity inversion line (PIL).',\n",
       "    'The model shows a strong correlation between Grad-CAM values and flare occurrence rates, as well as with key SHARP parameters.',\n",
       "    'The methodology is well-documented, and the model is evaluated using multiple metrics, ensuring robustness.'],\n",
       "   'weaknesses': ['The reliance on JPG format data may introduce errors due to compression.',\n",
       "    \"The model's performance may vary with different input data resolutions and qualities.\",\n",
       "    'The study does not explore other potential attribution methods that could provide additional insights.',\n",
       "    'The analysis is limited to a specific set of SHARP parameters, potentially overlooking other relevant physical parameters.']},\n",
       "  'reuse_potential': ['The methodology and model can be adapted for other solar activity prediction tasks.',\n",
       "   'The use of guided backpropagation and Grad-CAM can be extended to interpret other CNN-based models in solar physics.',\n",
       "   'The correlation analysis between Grad-CAM values and physical parameters can be applied to other datasets and models.']},\n",
       " {'title': 'Improved AI-generated Solar Farside Magnetograms by STEREO and SDO Data Sets and Their Release',\n",
       "  'author': 'Jeong et al.',\n",
       "  'id': '10.3847/2041-8213/ac91c1',\n",
       "  'data': ['SDO/AIA EUV images (304, 193, 171 Å)',\n",
       "   'SDO/HMI LOS magnetograms',\n",
       "   'STEREO/EUVI EUV images (304, 195, 171 Å)'],\n",
       "  'code_link': 'https://github.com/JeongHyunJin/Pix2PixCC',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'SciPy',\n",
       "   'Astropy',\n",
       "   'SunPy'],\n",
       "  'task': 'Solar farside magnetogram generation',\n",
       "  'abstract': 'The paper introduces an improved deep-learning model, Pix2PixCC, to generate more realistic solar farside magnetograms using data from the Solar Terrestrial Relations Observatory (STEREO) and Solar Dynamics Observatory (SDO). The model incorporates correlation coefficients (CCs) in its objective functions and uses input data sets that include solar farside STEREO extreme-ultraviolet (EUV) observations along with the nearest frontside SDO data pairs of EUV observations and magnetograms. The generated magnetograms show improved consistency with real magnetograms, achieving high correlation coefficients for full disk, active regions, and quiet regions. The AI-generated magnetograms are publicly available at the Korean Data Center for SDO.',\n",
       "  'models': ['Pix2PixCC (modified Pix2Pix with correlation coefficients)'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['EUV images and magnetograms'],\n",
       "  'baselines': ['Pix2Pix (KPL19)', 'Pix2PixHD (J20)'],\n",
       "  'approach_used': ['Deep learning-based image translation',\n",
       "   'Correlation coefficient-based loss function',\n",
       "   'Multimodal data fusion'],\n",
       "  'methodology': \"The Pix2PixCC model is trained using a combination of STEREO and SDO data. The generator network produces target-like data from input images, while the discriminator distinguishes between real and generated data pairs. The inspector computes correlation coefficients between target and generated data to ensure realistic outputs. The model uses a combination of least-squares GAN loss, feature matching loss, and CC loss to optimize the generator and discriminator. The training data consists of SDO/AIA EUV images and SDO/HMI magnetograms, with reference data pairs from one solar rotation prior to provide historical magnetic field information. The evaluation data sets are used to compute objective measures and assess the model's performance.\",\n",
       "  'metrics': ['Pixel-to-pixel correlation coefficients (CCs)',\n",
       "   'Total unsigned magnetic flux (TUMF)',\n",
       "   'Net magnetic flux (NMF)',\n",
       "   'Structural Similarity Index (SSIM)'],\n",
       "  'limitations': ['Difficulty in predicting small-scale magnetic field configurations accurately.',\n",
       "   'Potential inaccuracies in polarity distribution for rapidly emerging active regions not observed in reference data.',\n",
       "   'Dependence on the quality and availability of STEREO and SDO data.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Improved accuracy in generating solar farside magnetograms with high correlation coefficients.',\n",
       "    'Incorporation of correlation coefficients in the loss function enhances the realism of generated magnetograms.',\n",
       "    \"Use of multimodal data (EUV images and magnetograms) improves the model's ability to capture complex magnetic field distributions.\",\n",
       "    'Publicly available AI-generated magnetograms facilitate further research and applications in solar physics.'],\n",
       "   'weaknesses': ['The model may struggle with small-scale magnetic features and rapidly emerging active regions.',\n",
       "    \"Dependence on historical data limits the model's ability to predict unprecedented magnetic field changes.\",\n",
       "    'The resolution of generated magnetograms is limited by the binning process used during evaluation.']},\n",
       "  'reuse_potential': ['The publicly available AI-generated magnetograms can be used for continuous monitoring of solar activity.',\n",
       "   'Improved data can enhance studies in space weather prediction and solar dynamics.',\n",
       "   'The model and methodology can be adapted for other image translation tasks in astrophysics and beyond.']},\n",
       " {'title': 'Construction of global IGS-3D electron density (Ne) model by deep learning',\n",
       "  'author': 'Ji et al.',\n",
       "  'id': '10.1016/j.jastp.2024.106370',\n",
       "  'data': ['International Global Navigation Satellite Systems (GNSS) Service (IGS) total electron content (TEC) data',\n",
       "   'IRI-2016 model vertical electron density profiles',\n",
       "   'Incoherent scatter radar (ISR) data from Jicamarca, Millstone Hill, and EISCAT stations'],\n",
       "  'task': 'Global 3-D electron density modeling',\n",
       "  'abstract': \"The study presents a deep learning-based method to construct a global 3-D electron density (Ne) model using International Global Navigation Satellite Systems (GNSS) Service (IGS) total electron content (TEC) data. The model, called the IGS-3D Ne model, generates vertical electron density profiles from TEC values using a Multi-Layer Perceptron (MLP). The model was trained using IRI-2016 data from 2001 to 2008, validated with data from 2009 and 2014, and tested with data from 2010 to 2013. Evaluation against incoherent scatter radar (ISR) data at three stations (Jicamarca, Millstone Hill, and EISCAT) showed that the IGS-3D Ne model's electron density profiles were closer to ISR observations than those from the IRI model, particularly at high latitudes. The model demonstrated improved accuracy, especially during geomagnetic disturbances, suggesting its potential for enhancing global electron density predictions.\",\n",
       "  'models': ['Multi-Layer Perceptron (MLP)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Deep learning-based inversion method',\n",
       "   'Integration of electron density to calculate TEC'],\n",
       "  'methodology': 'The study employed a two-step approach to develop the IGS-3D Ne model. First, an MLP-based model was trained to generate vertical electron density profiles from TEC values using IRI-2016 model data. The training dataset included pairs of TEC values and corresponding electron density profiles from 2001 to 2008, with validation conducted using data from 2009 and 2014. The model was then tested on data from 2010 to 2013. In the second step, the trained model was used to generate global electron density profiles using IGS TEC data as input. The performance of the IGS-3D Ne model was evaluated by comparing its electron density profiles with ISR data at three stations: Jicamarca, Millstone Hill, and EISCAT. The model demonstrated improved accuracy over the IRI model, particularly at high latitudes and during geomagnetic disturbances.',\n",
       "  'metrics': ['Root Mean Square Error (RMSE)'],\n",
       "  'limitations': [\"The IRI model's limitations at high latitudes and during geomagnetic disturbances may affect the training data quality.\",\n",
       "   'The model assumes minimal plasmaspheric contribution to IGS TEC, which may introduce errors during nighttime conditions.',\n",
       "   \"The model's performance is dependent on the accuracy of IGS TEC data, which may vary with solar and geomagnetic conditions.\"],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The IGS-3D Ne model improves upon the IRI model, particularly at high latitudes and during geomagnetic disturbances.',\n",
       "    'The model successfully uses only TEC as input, simplifying the data requirements compared to other models that require additional parameters.',\n",
       "    'The deep learning-based inversion method shows potential for real-time global electron density prediction.',\n",
       "    \"The model's performance is validated against ISR data, providing a robust evaluation of its accuracy.\"],\n",
       "   'weaknesses': [\"The model's reliance on IRI-2016 data for training may limit its accuracy, particularly in regions where the IRI model performs poorly.\",\n",
       "    'The assumption of minimal plasmaspheric contribution to IGS TEC could lead to errors, especially during nighttime.',\n",
       "    \"The model's performance during extreme geomagnetic conditions is not extensively tested, which may limit its applicability in such scenarios.\",\n",
       "    'The study does not provide a publicly accessible code repository, which could hinder reproducibility and further research.']},\n",
       "  'reuse_potential': ['The IGS-3D Ne model can be reused for real-time global electron density prediction, which is valuable for space weather monitoring and satellite navigation.',\n",
       "   'The methodology can be adapted to other ionospheric modeling tasks, such as predicting electron density variations during solar events.',\n",
       "   \"The model's reliance on TEC data makes it compatible with existing GNSS infrastructure, facilitating integration into operational systems.\",\n",
       "   \"Future work could explore the model's performance with additional input parameters or alternative deep learning architectures to further improve accuracy.\"]},\n",
       " {'title': 'Generation of He I 1083 nm Images from SDO AIA Images by Deep Learning',\n",
       "  'author': 'Son et al.',\n",
       "  'id': '10.3847/1538-4357/ac15f8',\n",
       "  'data': ['SDO/AIA 19.3 nm images',\n",
       "   'SDO/AIA 30.4 nm images',\n",
       "   'He I 1083 nm images from NSO/SOLIS'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['SunPy', 'AIAPrep'],\n",
       "  'task': 'Generation of He I 1083 nm images',\n",
       "  'abstract': 'The study presents a deep learning method (pix2pixHD) based on conditional Generative Adversarial Networks (cGAN) to generate He I 1083 nm images from SDO/AIA images. Three models were developed: Model I (single-input SDO/AIA 19.3 nm), Model II (single-input 30.4 nm), and Model III (double-input 19.3 nm and 30.4 nm). The models successfully generated He I 1083 nm images with high correlations, with Model III showing the best performance in terms of correlation coefficient (CC) and root mean square error (RMSE). The synthetic images showed well-defined observational features such as active regions, filaments, and coronal holes, demonstrating the potential to produce He I 1083 nm images with higher cadence and without data gaps.',\n",
       "  'models': ['pix2pixHD', 'cGAN'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['Image-to-image translation'],\n",
       "  'baselines': ['N/A'],\n",
       "  'approach_used': ['Deep learning-based image generation',\n",
       "   'Conditional Generative Adversarial Networks (cGAN)',\n",
       "   'Pix2pixHD architecture'],\n",
       "  'methodology': 'The study utilized the pix2pixHD model, a deep learning method for high-resolution image-to-image translation. Three models were trained: Model I used SDO/AIA 19.3 nm images as input, Model II used 30.4 nm images, and Model III used both 19.3 nm and 30.4 nm images. The target data were He I 1083 nm images from NSO/SOLIS. The models were trained for 180,000 iterations, and the best-performing model was selected based on evaluation metrics. The pix2pixHD architecture includes a generator and two discriminators, which help in generating globally consistent images with finer details.',\n",
       "  'metrics': ['Correlation Coefficient (CC)', 'Root Mean Square Error (RMSE)'],\n",
       "  'limitations': ['The study acknowledges that limb darkening was not well-compensated in the He I 1083 nm data, potentially hiding polar coronal holes.',\n",
       "   'The quality of the generated images depends on the quality and availability of input SDO/AIA images.',\n",
       "   \"The model's performance on filament structures is less accurate compared to active regions and coronal holes.\",\n",
       "   'The study suggests that more training data could improve the accuracy of filament representation.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The models successfully generated He I 1083 nm images with high spatial resolution and uniform quality.',\n",
       "    'Model III, which uses both 19.3 nm and 30.4 nm images as input, showed the best performance in terms of CC and RMSE.',\n",
       "    'The synthetic images can fill observational gaps and provide high-cadence data, useful for studying the time evolution of chromospheric and coronal phenomena.',\n",
       "    'The study is the first to generate ground-based data using deep learning methods.'],\n",
       "   'weaknesses': ['The generated images may have limitations in capturing fine details of filaments.',\n",
       "    \"The model's effectiveness is dependent on the quality of input data, which may vary due to instrumental or atmospheric conditions.\",\n",
       "    'The study did not address the potential limitations of the model in handling data from different solar cycles or extreme solar events.']},\n",
       "  'reuse_potential': ['The methodology can be extended to generate other types of solar images or applied to different wavelengths.',\n",
       "   'The synthetic He I 1083 nm images can be used for continuous monitoring of solar features such as filaments, active regions, and coronal holes.',\n",
       "   'The approach can potentially be used to modernize historical solar data by generating consistent, high-quality images.']},\n",
       " {'title': 'Can we properly determine differential emission measures from Solar Orbiter/EUI/FSI with deep learning?',\n",
       "  'author': 'Youn et al.',\n",
       "  'id': '10.1051/0004-6361/202450000',\n",
       "  'data': ['SDO/AIA datasets', 'Solar Orbiter/EUI/FSI datasets'],\n",
       "  'code_link': 'https://github.com/ianan/demreg/',\n",
       "  'packages_used': ['PyTorch', 'Astropy', 'aiapy', 'SunPy', 'NumPy'],\n",
       "  'task': 'Differential Emission Measure (DEM) determination using deep learning',\n",
       "  'abstract': \"The study addresses whether differential emission measures (DEMs) can be accurately determined using Solar Orbiter/EUI/FSI and AI-generated extreme UV (EUV) data. The FSI's limited observation channels (174 and 304 Å) pose challenges for DEM analysis. The authors trained deep learning models using the Pix2PixCC architecture on SDO/AIA datasets to generate five additional EUV channels (94, 131, 193, 211, and 335 Å). These AI-generated channels, combined with FSI data, were used to compute DEMs, which were then compared with those derived from SDO/AIA observations. The results show that the DEMs from both datasets are consistent, indicating that deep learning can effectively augment FSI data for accurate DEM determination.\",\n",
       "  'models': ['Pix2PixCC'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['N/A'],\n",
       "  'approach_used': ['Image-to-image translation using deep learning',\n",
       "   'Regularized inversion for DEM calculation'],\n",
       "  'methodology': 'The study involved training deep learning models (Pix2PixCC) on SDO/AIA datasets to generate five EUV channels from two input channels (171 and 304 Å). These models were then applied to Solar Orbiter/EUI/FSI data to generate the missing EUV channels. The generated data were used alongside FSI observations to compute DEMs, which were compared with DEMs derived from SDO/AIA data. The comparison was conducted during periods when Solar Orbiter and SDO were in inferior conjunction, ensuring similar observational conditions. The DEM calculation employed a regularized inversion method, and intercalibration techniques were used to align data from the two instruments.',\n",
       "  'metrics': ['Pearson Correlation Coefficient (CC)',\n",
       "   'Root Mean Square Error (RMSE)',\n",
       "   'Normalized Root Mean Square Error (NRMSE)'],\n",
       "  'limitations': ['Discrepancies in contrast between AI-generated and observed images, particularly in extremely dark or bright regions.',\n",
       "   'Potential errors in DEM calculations due to differences in instrument response functions.',\n",
       "   'Challenges in intercalibration between SDO/AIA and Solar Orbiter/EUI/FSI data.',\n",
       "   'Three-dimensional morphology of coronal loops introduces errors when comparing DEMs from different vantage points.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Successful generation of five EUV channels from two input channels using deep learning.',\n",
       "    'High correlation between AI-generated and observed EUV images.',\n",
       "    'Consistent DEM results between Solar Orbiter/EUI/FSI and SDO/AIA datasets.',\n",
       "    'Potential for application in future missions with limited observational channels.'],\n",
       "   'weaknesses': ['Limitations in handling extreme events like solar flares.',\n",
       "    'Dependence on intercalibration techniques, which may introduce errors.',\n",
       "    'Challenges in accurately comparing DEMs from different vantage points due to the 3D nature of coronal structures.']},\n",
       "  'reuse_potential': ['The methodology can be extended to other solar observation missions with limited channels.',\n",
       "   'Potential for creating global temperature maps of the Sun using stereoscopic observations.',\n",
       "   'Useful for future missions at Lagrangian points L4 and L5 where weight constraints limit the number of observational channels.']},\n",
       " {'title': 'Fast Reconstruction of 3D Density Distribution around the Sun Based on the MAS by Deep Learning',\n",
       "  'author': 'Rahman et al.',\n",
       "  'id': '10.3847/1538-4357/acc0c3',\n",
       "  'data': ['Photospheric solar magnetic fields (input)',\n",
       "   '3D electron density distribution from MAS simulation (output)',\n",
       "   'SOHO/LASCO C3 coronagraph data (comparison)'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['SunPy', 'PyTorch', 'NumPy'],\n",
       "  'task': '3D coronal electron density reconstruction',\n",
       "  'abstract': 'This study introduces a deep learning-based approach using the pix2pixHD model to generate 3D coronal electron density distributions from photospheric solar magnetic fields. The method significantly reduces computation time compared to traditional MHD simulations like MAS (Magnetohydrodynamic Algorithm outside a Sphere). The AI-generated densities are highly consistent with MAS-simulated data, with an average correlation coefficient of 0.97. The approach enables near-real-time space weather modeling and demonstrates potential for integration with observational data from missions like Solar Orbiter and Parker Solar Probe.',\n",
       "  'models': ['pix2pixHD',\n",
       "   'U-Net (generator)',\n",
       "   'Conditional GAN (cGAN) with multiscale discriminator'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Image-to-image translation',\n",
       "   'Generative adversarial networks (GANs)',\n",
       "   'Least Squares GAN (LSGAN)',\n",
       "   'Feature matching loss'],\n",
       "  'methodology': 'The study uses a pix2pixHD-based deep learning model to generate 3D coronal electron density distributions from photospheric magnetic field data. The model consists of a U-Net generator and a multiscale discriminator, trained using LSGAN and feature matching loss. The input data are synoptic maps of photospheric magnetic fields, and the output is the 3D electron density distribution up to 30 solar radii. The model is trained on 122 Carrington rotations (CRs) and tested on 33 CRs, covering solar minimum and maximum periods. Data augmentation techniques like flipping and rotation are applied to enhance the training set. The AI-generated densities are compared with MAS simulations and SOHO/LASCO C3 coronagraph data.',\n",
       "  'metrics': [\"Pearson's correlation coefficient (CC)\",\n",
       "   'Normalized root mean square error (NRMSE)'],\n",
       "  'limitations': ['Limited to MAS simulation data, which may not capture all real-world complexities.',\n",
       "   'Performance varies between solar minimum and maximum periods due to differences in coronal structure complexity.',\n",
       "   'Dependence on the quality of input photospheric magnetic field data.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Significant reduction in computation time compared to MHD simulations.',\n",
       "    'High correlation (0.97) between AI-generated and MAS-simulated densities.',\n",
       "    'Potential for near-real-time space weather forecasting.',\n",
       "    'Compatibility with observational data from missions like Solar Orbiter and Parker Solar Probe.'],\n",
       "   'weaknesses': ['Dependence on MAS simulation data, which may introduce biases.',\n",
       "    'Variability in performance between solar minimum and maximum periods.',\n",
       "    'Limited by the resolution and quality of input magnetic field data.']},\n",
       "  'reuse_potential': ['The model can be adapted for other solar parameters like temperature and velocity.',\n",
       "   'Potential integration with real-time observational data for improved space weather predictions.',\n",
       "   'Applicability to other heliospheric and astrophysical simulations.']},\n",
       " {'title': 'Solar farside magnetograms from deep learning analysis of STEREO/EUVI data',\n",
       "  'author': 'Kim et al.',\n",
       "  'id': '10.1038/s41550-019-0714-9',\n",
       "  'data': ['SDO/AIA 304-Å images',\n",
       "   'SDO/HMI line-of-sight magnetograms',\n",
       "   'STEREO/EUVI 304-Å images'],\n",
       "  'code_link': 'https://github.com/tykimos/SolarMagGAN',\n",
       "  'packages_used': ['NumPy', 'Keras'],\n",
       "  'task': 'Generation of farside solar magnetograms using deep learning',\n",
       "  'abstract': 'The paper presents a deep learning model based on conditional generative adversarial networks (cGANs) to generate farside solar magnetograms from STEREO/Extreme UltraViolet Imager (EUVI) 304-Å images. The model is trained using pairs of Solar Dynamics Observatory (SDO)/Atmospheric Imaging Assembly (AIA) 304-Å images and SDO/Helioseismic and Magnetic Imager (HMI) magnetograms. The generated magnetograms are evaluated by comparing them with SDO/HMI magnetograms, showing high correlation and accuracy in replicating Hale-patterned active regions. The study demonstrates the potential of using deep learning for image-to-image translation in scientific data, specifically in solar physics for monitoring the temporal evolution of magnetic fields on the farside of the Sun.',\n",
       "  'models': ['Conditional Generative Adversarial Networks (cGANs)'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': [],\n",
       "  'approach_used': ['Image-to-image translation using cGANs',\n",
       "   'Training on paired SDO/AIA and SDO/HMI data',\n",
       "   'Evaluation using correlation and error metrics'],\n",
       "  'methodology': 'The study uses a cGAN-based deep learning model to translate SDO/AIA 304-Å images into magnetograms. The model is trained on paired datasets of SDO/AIA images and SDO/HMI magnetograms from 2011 to 2017, excluding September and October for evaluation. The evaluation involves comparing AI-generated magnetograms with SDO/HMI magnetograms using metrics such as correlation coefficient (CC), relative error (R1), and normalized mean square error (R2). The model is then applied to STEREO/EUVI 304-Å images to generate farside magnetograms, demonstrating its capability to monitor the evolution of solar active regions.',\n",
       "  'metrics': ['Correlation Coefficient (CC)',\n",
       "   'Relative Error (R1)',\n",
       "   'Normalized Mean Square Error (R2)',\n",
       "   'Pixel-to-pixel correlation'],\n",
       "  'limitations': ['The model may not accurately generate the tilt angle between sunspots.',\n",
       "   'The model is trained on data from the 24th solar cycle and may not be effective for odd solar cycles.',\n",
       "   'The discrepancy between chromospheric EUV emissions and photospheric magnetic fields can lead to inaccuracies in detailed structures.',\n",
       "   'Magnetic flux measurements near the solar limb are underestimated due to projection effects.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['High correlation between AI-generated and SDO/HMI magnetograms, especially for active regions.',\n",
       "    'Successful replication of Hale-patterned active regions.',\n",
       "    'Potential for monitoring the temporal evolution of magnetic fields on the farside of the Sun.',\n",
       "    'Application of deep learning to scientific data, demonstrating broader potential in astronomy and geophysics.'],\n",
       "   'weaknesses': ['Limitations in accurately generating tilt angles between sunspots.',\n",
       "    'Potential ineffectiveness for odd solar cycles due to training on the 24th solar cycle data.',\n",
       "    'Overestimation of total unsigned magnetic flux (TUMF) in some cases.',\n",
       "    'Challenges in precise reconstruction of photospheric magnetic fields from chromospheric emissions.']},\n",
       "  'reuse_potential': ['The model can be extended to other multiwavelength observations in astronomy and geophysics.',\n",
       "   'Potential for application in various scientific fields that use different types of sensor images.',\n",
       "   'Code and datasets are publicly available, facilitating further research and adaptations.']},\n",
       " {'title': 'Three-day Forecasting of Solar Wind Speed Using SDO/AIA Extreme-ultraviolet Images by a Deep-learning Model',\n",
       "  'author': 'Son et al.',\n",
       "  'id': '10.3847/1538-4357/ace04e',\n",
       "  'data': ['Solar Dynamics Observatory/Atmospheric Imaging Assembly (SDO/AIA) 211 and 193 Å images',\n",
       "   'OMNIWeb solar wind speed data'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['SolarSoft library',\n",
       "   'TensorFlow/PyTorch (implied by deep learning architecture)'],\n",
       "  'task': 'Solar wind speed prediction',\n",
       "  'abstract': 'The study presents a deep-learning model to forecast solar wind speed for the next 3 days with a 6-hour cadence. The model uses SDO/AIA 211 and 193 Å images along with solar wind speed data from the previous 5 days as input. The model architecture consists of a convolutional layer-based network for images and a dense layer-based network for solar wind speed data. The model successfully predicts solar wind speed, achieving an RMSE of 37.4 to 68.2 km/s and a correlation coefficient of 0.92 to 0.67 for prediction times ranging from 6 to 72 hours. The model outperforms previous studies and effectively predicts sudden increases in solar wind speed caused by equatorial coronal holes. However, it struggles with predicting enhancements caused by coronal mass ejections (CMEs).',\n",
       "  'models': ['Convolutional Neural Network (CNN)',\n",
       "   'Long Short-Term Memory (LSTM)',\n",
       "   'Dense Neural Network'],\n",
       "  'hybrid_model': True,\n",
       "  'multimodal': ['Image data (SDO/AIA)',\n",
       "   'Time-series data (solar wind speed)'],\n",
       "  'baselines': ['Wang-Sheely-Arge-ENLIL (WSA-ENLIL) model'],\n",
       "  'approach_used': ['Deep learning for sequential prediction',\n",
       "   'Multimodal data fusion (images and time-series)',\n",
       "   'Inception blocks for image processing'],\n",
       "  'methodology': 'The study uses a deep-learning model combining a CNN-based network for processing SDO/AIA EUV images and a dense layer-based network for processing solar wind speed data. The CNN network includes Inception blocks and an LSTM layer to capture temporal dependencies. The model is trained on data from 2010 to 2020, divided into training (January–August), validation (September), and test (October–December) sets. The model predicts solar wind speeds for the next 3 days with a 6-hour cadence.',\n",
       "  'metrics': ['Root Mean Square Error (RMSE)', 'Correlation Coefficient (CC)'],\n",
       "  'limitations': ['The model cannot predict solar wind speed enhancements caused by coronal mass ejections (CMEs).',\n",
       "   'The model may be biased toward solar cycle 24, which was relatively weak, and may require additional training data for application in solar cycle 25.',\n",
       "   \"The model's performance is less accurate during solar maximum phases due to increased CME activity.\"],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The model successfully predicts solar wind speed with high accuracy, outperforming previous models.',\n",
       "    'The model effectively captures sudden increases in solar wind speed caused by equatorial coronal holes.',\n",
       "    'The multimodal approach combining image and time-series data improves prediction accuracy.',\n",
       "    'The model demonstrates potential for real-time space weather forecasting applications.'],\n",
       "   'weaknesses': ['The model struggles to predict solar wind speed enhancements caused by CMEs, which limits its applicability during high solar activity periods.',\n",
       "    \"The model's performance may degrade when applied to different solar cycles without additional training data.\",\n",
       "    'The study does not provide a publicly accessible code repository, which could hinder reproducibility.']},\n",
       "  'reuse_potential': ['The model can be adapted for near-real-time forecasting by integrating real-time data feeds from sources like OMNIWeb or satellite observations.',\n",
       "   'The approach can be extended to predict solar wind speeds at different points in space, such as L4 or L5 missions, with appropriate observational data.',\n",
       "   'The methodology can be applied to other space weather forecasting tasks, such as predicting geomagnetic storms or solar flare activity.']},\n",
       " {'title': 'Generation of High-resolution Solar Pseudo-magnetograms from Ca II K Images by Deep Learning',\n",
       "  'author': 'Shin et al.',\n",
       "  'id': '10.3847/2041-8213/ab944d',\n",
       "  'data': ['Ca II K 393.3 nm images from the Precision Solar Photometric Telescope at the Rome Observatory',\n",
       "   'Line-of-sight magnetograms from the Helioseismic and Magnetic Imager (HMI) at the Solar Dynamics Observatory'],\n",
       "  'code_link': 'https://github.com/NoelShin/Ca2Mag',\n",
       "  'packages_used': ['PyTorch', 'scikit-image', 'PIL', 'NumPy'],\n",
       "  'task': 'Generation of high-resolution pseudo-magnetograms from Ca II K images',\n",
       "  'abstract': 'The paper presents a deep learning model based on conditional generative adversarial networks (cGANs) to generate high-resolution (1024x1024 pixels) pseudo-magnetograms from Ca II K images. The model, pix2pixHD, is specifically designed for high-resolution image translation tasks. The study uses Ca II K images from the Rome Observatory and magnetograms from the Helioseismic and Magnetic Imager (HMI) at the Solar Dynamics Observatory. The model shows high consistency in generating realistic magnetograms, with a mean correlation coefficient of 0.99 for total unsigned magnetic flux and 0.74 for pixel-to-pixel correlation after 8x8 binning. The results suggest the feasibility of producing high-resolution solar magnetograms from historical Ca II data.',\n",
       "  'models': ['pix2pixHD'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['Simple pixel-to-pixel calibration curve'],\n",
       "  'approach_used': ['Deep learning-based image translation using cGANs'],\n",
       "  'methodology': \"The methodology involves using a pix2pixHD model, a variant of cGAN, to translate Ca II K images into pseudo-magnetograms. The model consists of a generator and two discriminators, which are trained to distinguish between real and generated magnetograms. The generator aims to produce realistic magnetograms that the discriminators cannot differentiate from real ones. The training process includes data augmentation techniques such as random rotation to improve the model's performance. The evaluation metrics include total unsigned magnetic flux, pixel-to-pixel correlation, relative error, and structural similarity index (SSIM).\",\n",
       "  'metrics': ['Total Unsigned Magnetic Flux (TUMF)',\n",
       "   'Pixel-to-pixel Pearson Correlation Coefficient (CC)',\n",
       "   'Relative Error (R)',\n",
       "   'Structural Similarity Index (SSIM)'],\n",
       "  'limitations': ['The model struggles with complex magnetic fields near polarity inversion lines, often failing to assign proper polarities in active regions.',\n",
       "   'The pixel-to-pixel correlations for magnetic flux densities in quiet regions are significantly lower compared to active regions.',\n",
       "   'The model slightly underestimates total unsigned magnetic flux values.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['High correlation in total unsigned magnetic flux (CC=0.99).',\n",
       "    'Effective generation of high-resolution pseudo-magnetograms (1024x1024 pixels).',\n",
       "    'Successful application to historical ground-based data, offering potential for long-term solar magnetic field studies.',\n",
       "    'Open-source code availability enhances reproducibility and further research.'],\n",
       "   'weaknesses': ['Lower pixel-to-pixel correlation in quiet regions (CC=0.24).',\n",
       "    'Difficulty in accurately reconstructing complex magnetic structures.',\n",
       "    'Slight underestimation of total unsigned magnetic flux values.']},\n",
       "  'reuse_potential': ['The model can be applied to historical Ca II K data to generate pseudo-magnetograms for periods lacking direct magnetic field observations.',\n",
       "   'Potential for integration with other solar observation datasets to enhance long-term solar activity studies.',\n",
       "   'The methodology can be adapted for other image translation tasks in astronomy and related fields.']},\n",
       " {'title': 'Near-real-time 3D Reconstruction of the Solar Coronal Parameters Based on the Magnetohydrodynamic Algorithm outside a Sphere Using Deep Learning',\n",
       "  'author': 'Rahman et al.',\n",
       "  'id': '10.3847/1538-4357/ad1904',\n",
       "  'data': ['Synoptic maps of the photospheric magnetic field from 169 Carrington rotations (2010 June to 2023 February)',\n",
       "   'MAS (Magnetohydrodynamic Algorithm outside a Sphere) simulation data for density, magnetic field, radial velocity, and temperature'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['PyTorch', 'NumPy', 'Matplotlib', 'Skimage', 'SunPy'],\n",
       "  'task': '3D reconstruction of solar coronal parameters (density, magnetic field, radial velocity, and temperature) using deep learning',\n",
       "  'abstract': 'The study presents a deep learning-based approach to generate near-real-time 3D reconstructions of solar coronal parameters (density, magnetic field, radial velocity, and temperature) using the Pix2PixCC model. The model uses synoptic maps of the photospheric magnetic field as input and MAS simulation results as output. A total of 152 deep-learning models were trained and evaluated for each parameter, achieving an average correlation coefficient of 0.98. The AI-generated data showed consistency with MAS simulation data during both solar active and quiet periods. The deep-learning models significantly reduced computation time, taking about 16 seconds per parameter on an NVIDIA Titan XP GPU. The results can be used for near-real-time forecasting of heliospheric propagation of solar eruptions.',\n",
       "  'models': ['Pix2PixCC (improved version of Pix2PixHD)'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['MAS simulation model', 'Pix2PixHD'],\n",
       "  'approach_used': ['Generative Adversarial Networks (GANs)',\n",
       "   'Data augmentation',\n",
       "   'Interpolation techniques for alignment of parameters'],\n",
       "  'methodology': \"The study utilized the Pix2PixCC model, an improved version of Pix2PixHD, to generate 3D structures of solar coronal parameters from photospheric magnetic field data. The model incorporates a generator, discriminator, and inspector, with loss functions including feature matching (FM) loss, least-squares GAN (LSGAN) loss, and correlation coefficient (CC) loss. The training involved 152 deep-learning models for each parameter, using data from 169 Carrington rotations. Data augmentation was applied to enhance the training dataset, and interpolation techniques were used for alignment. The models were evaluated using Pearson's correlation coefficient (CC), normalized root mean square error (NRMSE), and normalized mean absolute error (NMAE).\",\n",
       "  'metrics': [\"Pearson's Correlation Coefficient (CC)\",\n",
       "   'Normalized Root Mean Square Error (NRMSE)',\n",
       "   'Normalized Mean Absolute Error (NMAE)'],\n",
       "  'limitations': ['Errors in AI-generated temperature maps at certain positions',\n",
       "   'Inconsistencies in AI-generated results during solar maximum periods',\n",
       "   'Dependence on the quality of synoptic maps of the photospheric magnetic field'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['High correlation coefficient (0.98) between AI-generated and MAS simulation data',\n",
       "    'Significant reduction in computation time (16 seconds per parameter)',\n",
       "    'Consistency in AI-generated data during both solar active and quiet periods',\n",
       "    'Potential for near-real-time forecasting of heliospheric propagation of solar eruptions'],\n",
       "   'weaknesses': ['Inconsistencies in AI-generated results during high solar activity',\n",
       "    'Limitations in accurately reproducing temperature maps at certain positions',\n",
       "    'Dependence on the accuracy of input synoptic maps']},\n",
       "  'reuse_potential': ['The AI-generated 3D structures can be used for analyzing solar observations and improving models of the solar corona and inner heliosphere.',\n",
       "   'Potential application in specifying boundary conditions for heliospheric simulation models.',\n",
       "   'Useful for near-real-time forecasting of solar eruptions and space weather events.']},\n",
       " {'title': 'Application of Deep Reinforcement Learning to Major Solar Flare Forecasting',\n",
       "  'author': 'Yi (Kangwoo) et al.',\n",
       "  'id': '10.3847/1538-4357/ac5d5b',\n",
       "  'data': ['Solar and Heliospheric Observatory/Michelson Doppler Imager (SOHO/MDI) magnetograms (1996-2010)',\n",
       "   'Solar Dynamics Observatory/Helioseismic and Magnetic Imager (SDO/HMI) magnetograms (2011-2019)',\n",
       "   'Geostationary Operational Environmental Satellite (GOES) X-ray flare data'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'SciPy',\n",
       "   'Astropy',\n",
       "   'SunPy'],\n",
       "  'task': 'Major solar flare forecasting',\n",
       "  'abstract': \"This study applies deep reinforcement learning, specifically Deep Q-Network (DQN) and Double DQN, to predict the daily occurrence of M- and X-class solar flares using full-disk magnetograms from SOHO/MDI and SDO/HMI, along with GOES X-ray flare data. The research demonstrates that deep reinforcement learning models outperform traditional convolutional neural network (CNN) models in terms of skill scores such as Heidke Skill Score (HSS), F1 score, True Skill Statistic (TSS), and Appleman's Skill Score (ApSS). The performance of these models is influenced by the reward function, learning method, and target agent update time.\",\n",
       "  'models': ['Deep Q-Network (DQN)',\n",
       "   'Double Deep Q-Network (Double DQN)',\n",
       "   'Convolutional Neural Network (CNN)'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['CNN model with the same structure'],\n",
       "  'approach_used': ['Deep reinforcement learning for imbalanced classification',\n",
       "   'Reward function optimization',\n",
       "   'Experience replay technique'],\n",
       "  'methodology': 'The study employs full-disk magnetograms from SOHO/MDI and SDO/HMI, along with GOES X-ray flare data, to train and test deep reinforcement learning models. The models use DQN and Double DQN algorithms to predict the occurrence of M- and X-class solar flares. The reward functions are designed to handle class imbalance issues, with different penalties and rewards for true positives, false positives, false negatives, and true negatives. The models are evaluated using skill scores such as HSS, F1, TSS, and ApSS, and their performance is compared to a baseline CNN model with the same structure.',\n",
       "  'metrics': ['Heidke Skill Score (HSS)',\n",
       "   'F1 score',\n",
       "   'True Skill Statistic (TSS)',\n",
       "   \"Appleman's Skill Score (ApSS)\"],\n",
       "  'limitations': ['The performance of the models may depend on the solar cycle phase of the test dataset.',\n",
       "   'The study does not use 10-fold cross-validation, which could lead to potential overfitting if similar data from the same time periods are included in both training and test sets.',\n",
       "   'The model structure and hyperparameters are optimized for CNN-based flare forecasting and may not be fully optimized for deep reinforcement learning.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The application of deep reinforcement learning to solar flare forecasting is innovative and shows promising results.',\n",
       "    'The models outperform traditional CNN models in terms of skill scores.',\n",
       "    'The study addresses the class imbalance issue effectively using reward function optimization.',\n",
       "    'The methodology is well-documented, and the use of standard evaluation metrics ensures a comprehensive assessment of model performance.'],\n",
       "   'weaknesses': ['The computational training time for reinforcement learning models is significantly higher than for CNN models.',\n",
       "    'The performance of the models may vary depending on the solar cycle phase, which is not fully addressed in the study.',\n",
       "    'The lack of 10-fold cross-validation may limit the generalizability of the results.',\n",
       "    'The hyperparameters and model structure are primarily optimized for CNN-based forecasting, potentially limiting the performance of the reinforcement learning models.']},\n",
       "  'reuse_potential': ['The methodology and models can be adapted for other imbalanced classification problems beyond solar flare forecasting.',\n",
       "   'The use of reinforcement learning for handling class imbalance issues can be applied in various domains such as medical diagnosis, fraud detection, and rare event prediction.',\n",
       "   'The reward function optimization technique can be reused in other reinforcement learning applications to improve performance on imbalanced datasets.']},\n",
       " {'title': 'Six-hour Prediction of Interplanetary Magnetic Field $B_{z}$ Profiles for Strong Southward Cases by Deep Learning',\n",
       "  'author': 'Son et al.',\n",
       "  'id': '10.3847/1538-4357/ad393d',\n",
       "  'data': ['OMNIWeb solar wind and IMF data (2000–2022)'],\n",
       "  'code_link': 'https://github.com/Jihyeon-ing/Bz_prediction',\n",
       "  'packages_used': ['TensorFlow/Keras (for BiLSTM implementation)',\n",
       "   'Scikit-learn (for MLP and MLR baselines)',\n",
       "   'NumPy/Pandas (data processing)',\n",
       "   'Matplotlib/Seaborn (visualization)'],\n",
       "  'task': 'Prediction of interplanetary magnetic field (IMF) $B_{z}$ profiles for strong southward cases (6-hour forecast)',\n",
       "  'abstract': 'This study introduces a deep learning model using bidirectional long short-term memory (BiLSTM) networks to predict the 6-hour interplanetary magnetic field (IMF) $B_{z}$ component for southward cases. The model leverages solar wind data (speed, density, temperature) and IMF components ($B_{l}$, $B_{x}$, $B_{y}$, $B_{z}$) from OMNIWeb (2000–2022) to focus on geomagnetic conditions where $B_{z}$ drops below -3 nT for at least 6 hours. Using a 12-fold cross-validation approach, the ensemble model achieves an RMSE range of 1.75–2.55 nT, outperforming baseline models (multilayer perceptron and multiple linear regression). The model effectively captures decreasing and increasing phases of $B_{z}$, demonstrating reliable performance across varying geomagnetic conditions. This research highlights the potential of deep learning for short-term $B_{z}$ predictions, contributing to improved space weather forecasting.',\n",
       "  'models': ['Bidirectional Long Short-Term Memory (BiLSTM)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Time-series forecasting with sliding window technique',\n",
       "   '12-fold cross-validation',\n",
       "   'Ensemble modeling'],\n",
       "  'methodology': 'The study employs a BiLSTM model to predict the IMF $B_{z}$ component for strong southward cases. Input features include solar wind parameters (speed, density, temperature) and IMF components, structured as 12-hour sequences (24 time steps) with 30-minute resolution. The target is the subsequent 6-hour $B_{z}$ profile. The data set focuses on periods where $B_{z}$ drops below -3 nT for at least 6 hours, identified using a sliding window approach. The model is trained using 12-fold cross-validation, with each fold covering 8 months of data for training and 4 months for testing. Performance is evaluated using RMSE, MAE, and correlation coefficient, with comparisons against baseline models (MLP and MLR). The ensemble of 12 models demonstrates robust performance, particularly for longer prediction horizons.',\n",
       "  'metrics': ['Root Mean Square Error (RMSE)',\n",
       "   'Mean Absolute Error (MAE)',\n",
       "   'Pearson Correlation Coefficient (CC)'],\n",
       "  'limitations': ['Focus limited to strong southward $B_{z}$ cases (below -3 nT), excluding broader operational forecasting needs.',\n",
       "   'Model performance degrades for extreme $B_{z}$ fluctuations (e.g., -50 nT) due to limited training examples.',\n",
       "   'Lack of real-time validation for operational space weather applications.',\n",
       "   'Potential overfitting risks mitigated but not fully eliminated due to high parameter-to-data ratio.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['First study to predict $B_{z}$ profiles (not just minimum/maximum values) using deep learning.',\n",
       "    'Effective use of BiLSTM to capture nonlinear dependencies in solar wind data.',\n",
       "    'Robust performance across varying geomagnetic conditions, with RMSE improvements over baselines.',\n",
       "    'Potential for integration with global MHD simulations and empirical magnetic field models.',\n",
       "    'Open-source code availability for reproducibility.'],\n",
       "   'weaknesses': ['Limited to strong southward cases, reducing generalizability for operational forecasting.',\n",
       "    'Extreme $B_{z}$ events remain challenging due to data scarcity.',\n",
       "    'Sliding window approach may introduce temporal overlap in training data.',\n",
       "    'No adaptive early stopping or advanced regularization techniques applied.']},\n",
       "  'reuse_potential': ['Integration with solar wind speed prediction models for geomagnetic index forecasting (e.g., Dst, AE, Kp).',\n",
       "   \"Application in global MHD simulations to model Earth's magnetospheric response.\",\n",
       "   'Extension to real-time space weather alerts with broader $B_{z}$ value coverage.',\n",
       "   'Adaptation for other IMF component predictions or related heliophysical parameters.']},\n",
       " {'title': 'One-Day Forecasting of Global TEC Using a Novel Deep Learning Model',\n",
       "  'author': 'Lee (Sujin) et al.',\n",
       "  'id': '10.1029/2020SW002600',\n",
       "  'data': ['International GNSS Service (IGS) TEC maps (2003-2012)',\n",
       "   '1-day Center for Orbit Determination in Europe (CODE) prediction model'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['TensorFlow', 'Pix2Pix (cGAN)'],\n",
       "  'task': 'Global Total Electron Content (TEC) 1-day forecasting',\n",
       "  'abstract': 'The study presents a deep learning model based on conditional generative adversarial networks (cGANs) for forecasting global total electron content (TEC) maps one day in advance. The model uses IGS TEC maps from 2003 to 2012 for training and is tested during solar maximum (2013-2014) and solar minimum (2017-2018) periods. The model outperforms the 1-day CODE prediction model, showing better performance during both solar activity periods. The model successfully predicts global TEC maps using only previous TEC data, demonstrating the effectiveness of deep learning in space weather forecasting.',\n",
       "  'models': ['Conditional Generative Adversarial Network (cGAN)', 'Pix2Pix'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['1-day CODE prediction model'],\n",
       "  'approach_used': ['Image-to-image translation', 'Time-series forecasting'],\n",
       "  'methodology': 'The model uses a cGAN architecture, specifically Pix2Pix, to generate future TEC maps based on historical TEC data. The input consists of two images: the current IGS TEC map and the 1-day difference map between the current and previous day. The output is the predicted TEC map for the next day. The model is trained using a combination of L1 loss and cGAN loss, optimized with the ADAM solver. The training dataset spans 2003-2012, covering both solar maximum and minimum periods, while testing is conducted on datasets from 2013-2014 and 2017-2018.',\n",
       "  'metrics': ['Root Mean Square Error (RMSE)',\n",
       "   'Bias',\n",
       "   'Standard Deviation (STD)'],\n",
       "  'limitations': [\"The model's performance is affected by the availability and quality of training data, particularly during extreme solar activity.\",\n",
       "   'The model may not generalize well to periods of unusual geomagnetic activity not well-represented in the training data.',\n",
       "   'Real-time forecasting is limited by the latency of IGS TEC maps (11 days).'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The model successfully predicts global TEC maps with high accuracy, outperforming the 1-day CODE prediction model.',\n",
       "    'The use of cGANs allows the model to capture complex spatial patterns in TEC data.',\n",
       "    'The model demonstrates robustness across different solar activity periods.',\n",
       "    'The approach can be generalized to other image forecasting tasks in scientific research.'],\n",
       "   'weaknesses': [\"The model's reliance on historical TEC data may limit its performance during unprecedented geomagnetic conditions.\",\n",
       "    'The latency of IGS TEC maps restricts real-time applicability.',\n",
       "    'The model requires significant computational resources for training and optimization.']},\n",
       "  'reuse_potential': ['The methodology can be adapted for forecasting other geospatial or temporal datasets.',\n",
       "   \"The model's architecture can be reused for similar image-to-image translation tasks in other domains.\",\n",
       "   'Potential for integration with real-time data sources if latency issues are addressed.']},\n",
       " {'title': 'Real-time Extrapolation of Nonlinear Force-free Fields from Photospheric Vector Magnetic Fields Using a Physics-informed Neural Operator',\n",
       "  'author': 'Jeon et al.',\n",
       "  'id': '10.3847/2041-8213/ad33b0',\n",
       "  'data': ['Low and Lou semianalytical NLFFF model',\n",
       "   '2327 numerical NLFFFs from the ISEE database for solar active regions (ARs)'],\n",
       "  'code_link': 'https://github.com/mgjeon/rtmag',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'TorchMetrics',\n",
       "   'Matplotlib',\n",
       "   'NumPy',\n",
       "   'SciPy',\n",
       "   'Astropy',\n",
       "   'SunPy'],\n",
       "  'task': 'Real-time extrapolation of 3D nonlinear force-free fields (NLFFFs) from 2D photospheric vector magnetic fields',\n",
       "  'abstract': 'The study introduces a physics-informed neural operator (PINO) model designed to extrapolate 3D nonlinear force-free fields (NLFFFs) from 2D photospheric vector magnetic fields in real-time. The model is trained using physics loss from NLFFF partial differential equations and data loss from target NLFFFs. Validation is performed using an analytical NLFFF model, and the model is further trained and evaluated with 2327 numerical NLFFFs from 211 active regions in the ISEE database. The trained PINO model can generate an NLFFF within 1 second for any active region on a single consumer GPU, enabling real-time extrapolation. The AI-generated NLFFFs are qualitatively and quantitatively similar to the target NLFFFs, with magnetic energy trends aligning closely with those from other conventional methods.',\n",
       "  'models': ['Physics-informed Neural Operator (PINO)',\n",
       "   'U-shaped Neural Operator with six Fourier layers'],\n",
       "  'hybrid_model': True,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['Optimization methods (Wiegelmann et al. 2012)',\n",
       "   'Magnetohydrodynamic (MHD) relaxation methods (Inoue et al. 2013)',\n",
       "   'Physics-informed neural networks (PINNs) (Raissi et al. 2019)'],\n",
       "  'approach_used': ['Physics-informed loss',\n",
       "   'Data-driven loss',\n",
       "   'Neural operator architecture'],\n",
       "  'methodology': 'The PINO model is trained using a combination of physics loss (based on NLFFF PDEs) and data loss (comparing AI-generated NLFFFs with target NLFFFs). The model architecture is a U-shaped neural operator with six Fourier layers, designed for efficient training and robustness. The model is validated using an analytical NLFFF model and evaluated on numerical NLFFFs from the ISEE database. The performance is assessed using comparison metrics (e.g., vector correlation, Cauchy-Schwartz metric) and quality metrics (e.g., force-freeness, divergence-freeness).',\n",
       "  'metrics': ['Vector correlation metric (C_vec)',\n",
       "   'Cauchy-Schwartz metric (C_CS)',\n",
       "   'Normalized vector error (E_n)',\n",
       "   'Mean vector error (E_m)',\n",
       "   'Magnetic energy ratio (ε)',\n",
       "   'Current-weighted average of sine of angle between magnetic field and current density (σ_J)',\n",
       "   'Average magnitude of fractional flux increase (<|f_i|>)'],\n",
       "  'limitations': [\"The model's performance may degrade for active regions with out-of-distribution properties.\",\n",
       "   'Ensuring force-freeness and divergence-freeness in AI-generated NLFFFs is challenging.',\n",
       "   'The model requires high GPU memory, limiting batch size during training.',\n",
       "   'The PINO model does not accept coordinate inputs, unlike PINNs, which can achieve better force-freeness and divergence-freeness.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The PINO model enables real-time extrapolation of NLFFFs, generating results within 1 second on a consumer GPU.',\n",
       "    'The AI-generated NLFFFs are qualitatively and quantitatively similar to target NLFFFs.',\n",
       "    'The model is trained using both physics-informed and data-driven losses, ensuring compatibility with underlying physics.',\n",
       "    'The methodology is validated on both analytical and numerical NLFFF models, demonstrating robustness.',\n",
       "    \"The model's speed and efficiency make it suitable for real-time applications, such as solar flare prediction.\"],\n",
       "   'weaknesses': ['The quality metrics for force-freeness and divergence-freeness are not as strong as those of the target NLFFFs.',\n",
       "    'The model may struggle with active regions that have significantly different properties from the training data.',\n",
       "    \"The lack of coordinate inputs limits the model's ability to achieve the same level of force-freeness and divergence-freeness as PINNs.\",\n",
       "    'The model requires high GPU memory, which may limit scalability for larger datasets or higher resolutions.']},\n",
       "  'reuse_potential': ['The PINO model can be extended to other parametric PDE problems in solar physics and space weather research.',\n",
       "   'The real-time capability of the model makes it suitable for operational space weather forecasting.',\n",
       "   'The methodology can be adapted for full MHD equations, enabling more comprehensive reconstructions of the solar corona.']},\n",
       " {'title': 'Prediction of the Next Solar Rotation Synoptic Maps Using an Artificial Intelligence-based Surface Flux Transport Model',\n",
       "  'author': 'Jeong (Hyun-Jin) et al.',\n",
       "  'id': '10.3847/1538-4357/ad32f9',\n",
       "  'data': ['Solar Dynamics Observatory/Helioseismic and Magnetic Imager (SDO/HMI)',\n",
       "   'Solar and Heliospheric Observatory/Michelson Doppler Imager (SOHO/MDI)',\n",
       "   'National Solar Observatory/Global Oscillation Network Group (NSO/GONG) synoptic maps'],\n",
       "  'code_link': 'https://github.com/antyeates1983/sft_data',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'SunPy',\n",
       "   'Astropy',\n",
       "   'SciPy',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'Scikit-image'],\n",
       "  'task': 'Prediction of solar surface magnetic field evolution over the next solar rotation (27.2753 days)',\n",
       "  'abstract': 'The study introduces an AI-based Surface Flux Transport (SFT) model to predict the evolution of solar magnetic fields over the next solar rotation using deep learning. The model uses synoptic maps as input and generates predictions for the next rotation, demonstrating performance comparable to or better than traditional SFT models and persistent models. The AI model successfully captures key solar phenomena such as differential rotation, meridional flow, and magnetic diffusion, offering a promising tool for space weather forecasting.',\n",
       "  'models': ['Pix2PixCC', 'U-Net'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Deep learning-based prediction',\n",
       "   'Data augmentation',\n",
       "   'K-fold cross-validation'],\n",
       "  'methodology': \"The study employs a deep learning model based on the Pix2PixCC architecture, incorporating a U-Net generator, a discriminator, and an inspector. The model is trained on historical synoptic maps from SDO/HMI, SOHO/MDI, and NSO/GONG, augmented to enhance data diversity. The model's performance is evaluated using metrics such as RMSE, FSIM, and pixel-to-pixel correlation coefficients, and compared against traditional SFT and persistent models. The model successfully predicts large-scale magnetic field evolution and small-scale features, though it struggles with newly emerging active regions.\",\n",
       "  'metrics': ['Root Mean Square Error (RMSE)',\n",
       "   'Feature Similarity Index Measure (FSIM)',\n",
       "   'Pixel-to-pixel Pearson Correlation Coefficient (CC)'],\n",
       "  'limitations': ['Inability to predict newly emerging active regions during a solar rotation.',\n",
       "   'Dependence on historical data, limiting predictive accuracy during unusual solar activity.',\n",
       "   'Challenges in capturing fine-scale magnetic features as accurately as traditional models in some cases.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Effective prediction of large-scale magnetic field evolution.',\n",
       "    'Successful implementation of key solar phenomena like differential rotation and meridional flow.',\n",
       "    'Comparable or better performance than traditional SFT models in quantitative metrics.',\n",
       "    'Potential for iterative forecasting over multiple solar rotations.'],\n",
       "   'weaknesses': ['Difficulty in predicting newly emerging active regions.',\n",
       "    'Limited accuracy in capturing fine-scale magnetic features compared to traditional models in some scenarios.',\n",
       "    'Dependence on historical data may affect performance during anomalous solar activity.']},\n",
       "  'reuse_potential': ['The model can be integrated into space weather forecasting systems to improve predictions.',\n",
       "   'Potential for application in solar coronal and heliospheric numerical models.',\n",
       "   'Useful for studying long-term solar activity trends and cycles.']},\n",
       " {'title': 'Can Solar Limb Flare Prediction Be Properly Made by Extreme-ultraviolet Intensities?',\n",
       "  'author': 'Lee (Jaewon) et al.',\n",
       "  'id': '10.3847/2041-8213/ad5a5c',\n",
       "  'data': ['SDO/AIA 94 Å and 131 Å EUV intensities from 2010 to 2022',\n",
       "   'GOES X-ray flare fluxes',\n",
       "   'Heliophysics Event Knowledgebase (HEK) flare data'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['Python 3',\n",
       "   'Numpy',\n",
       "   'Matplotlib',\n",
       "   'Pandas',\n",
       "   'SunPy',\n",
       "   'PyTorch'],\n",
       "  'task': 'Solar limb flare prediction',\n",
       "  'abstract': 'The study investigates whether solar limb flare prediction can be effectively made using EUV intensity data, which is less affected by projection effects compared to solar white light and magnetogram data. The authors develop empirical and multilayer perceptron (MLP) models to forecast the probability of major solar limb flares within a day. Using SDO/AIA 94 and 131 Å data, which have high correlations with X-ray flare fluxes, the models are trained and tested on 240 flares of M1.0 class or stronger located near the limb region. The results show that both empirical (AUC=0.85) and MLP (AUC=0.84) models perform significantly better than random forecasting (AUC=0.50) and outperform the climatological model. Additionally, the models successfully predict all 52 events during the test period, whereas models in the NASA/CCMC flare scoreboard only predict 22 events.',\n",
       "  'models': ['Empirical model', 'Multilayer Perceptron (MLP)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Data binning for empirical model',\n",
       "   'Supervised learning for MLP model',\n",
       "   'Binary classification with threshold optimization'],\n",
       "  'methodology': 'The study uses SDO/AIA 94 Å and 131 Å EUV intensities from 2010 to 2022, focusing on major flares (M1.0 or higher) near the solar limb (heliographic longitude of 60° or more). The data is preprocessed by downsampling, resizing, and applying logarithmic transformations to mitigate bias. The empirical model divides the data into bins and calculates flare occurrence probabilities, while the MLP model uses supervised learning with binary cross-entropy (BCE) and Score-Oriented Loss (SOL) functions. Both models are evaluated using metrics such as ROC-AUC, TSS, HSS, and BSS.',\n",
       "  'metrics': ['True Skill Statistics (TSS)',\n",
       "   'Heidke Skill Score (HSS)',\n",
       "   'Receiver Operating Characteristic - Area Under the Curve (ROC-AUC)',\n",
       "   'Brier Skill Score (BSS)'],\n",
       "  'limitations': ['Imbalanced dataset with non-flaring samples dominating, which may affect MLP performance.',\n",
       "   'Limited to major flares (M1.0 or higher) near the solar limb, potentially reducing generalizability.',\n",
       "   'Dependence on EUV data, which may have calibration challenges over time.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Effective use of EUV data for solar limb flare prediction, reducing projection effects.',\n",
       "    'Both empirical and MLP models show strong performance (AUC=0.85 and 0.84, respectively).',\n",
       "    'Models successfully predict all 52 test events, outperforming NASA/CCMC flare scoreboard models.',\n",
       "    'Provides probabilistic predictions, useful for operational risk assessment.'],\n",
       "   'weaknesses': [\"The imbalanced dataset may limit the MLP model's performance.\",\n",
       "    'Focus on a specific region (limb) and flare class (M1.0 or higher) may reduce broader applicability.',\n",
       "    'Calibration of EUV data over time introduces potential errors.']},\n",
       "  'reuse_potential': ['The methodology can be extended to other solar flare prediction tasks using different data sources.',\n",
       "   'The models can be integrated into ensemble forecasting systems for improved accuracy.',\n",
       "   'Potential application in space weather forecasting and risk assessment for solar activities.']},\n",
       " {'title': 'Deep Learning-based Fast Spectral Inversion of Hα and Ca II 8542 Line Spectra',\n",
       "  'author': 'Lee (Kyoung-Sun) et al.',\n",
       "  'id': '10.3847/1538-4357/ac9c47',\n",
       "  'data': ['Spectral line profiles of Hα and Ca II 8542 Å from the Fast Imaging Solar Spectrograph (FISS)',\n",
       "   '49 raster scans (~2,000,000 spectra) from FISS observations (2013-2015)'],\n",
       "  'code_link': 'https://github.com/snu-fiss/fisspy',\n",
       "  'packages_used': ['TensorFlow',\n",
       "   'Astropy',\n",
       "   'Fisspy',\n",
       "   'Keras',\n",
       "   'Matplotlib',\n",
       "   'NumPy',\n",
       "   'Scikit-learn',\n",
       "   'SciPy'],\n",
       "  'task': 'Spectral inversion for inferring physical parameters of solar chromospheric plasmas',\n",
       "  'abstract': 'The study presents a deep neural network (DNN) technique to expedite the Multilayer Spectral Inversion (MLSI) process for inferring physical parameters of solar chromospheric plasmas from Hα and Ca II 8542 Å line spectra. The DNN model is trained on spectral data from the Fast Imaging Solar Spectrograph (FISS) and achieves a 250-fold speedup compared to traditional MLSI, producing results in about 0.3-0.4 ms per line profile. The model successfully reproduces physical parameters with high accuracy and reliably captures temporal variations, enabling efficient analysis of large datasets for understanding chromospheric plasma conditions.',\n",
       "  'models': ['Fully connected neural network with skip connections and multi-branch architecture'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['MLSI (Multilayer Spectral Inversion)'],\n",
       "  'approach_used': ['Supervised learning',\n",
       "   'Data preprocessing (standardization, wavelength calibration, intensity normalization)',\n",
       "   'Skip connections and multi-branch architecture in DNN',\n",
       "   'Swish activation function',\n",
       "   'Xavier initialization',\n",
       "   'Adam optimizer with L2 regularization'],\n",
       "  'methodology': 'The study employs a DNN to replicate the MLSI process for spectral inversion, significantly reducing computational time. The DNN is trained on spectral profiles and corresponding physical parameters derived from MLSI. The architecture includes skip connections to mitigate vanishing gradients and multi-branch layers to enhance performance. The model is evaluated on its ability to reproduce physical parameters and spectral profiles, with metrics such as MAE, NRMSE, correlation coefficient, and R² score used to assess accuracy. The DNN demonstrates high precision and computational efficiency, making it suitable for large-scale analysis of solar chromospheric data.',\n",
       "  'metrics': ['Mean Absolute Error (MAE)',\n",
       "   'Normalized Root Mean Squared Error (NRMSE)',\n",
       "   'Correlation Coefficient (CC)',\n",
       "   'Coefficient of Determination (R² score)',\n",
       "   'Goodness of fit (ε_D) for synthesized spectra'],\n",
       "  'limitations': [\"The model's performance is dependent on the quality of MLSI fits; poorly fitted spectra by MLSI result in less accurate DNN predictions.\",\n",
       "   'Training data is biased towards active regions (ARs), potentially limiting reliability for quiet regions (QRs) or limb observations.',\n",
       "   'The model may not handle atypical spectral profiles, such as those from flares or fast-moving plasma, which require more sophisticated modeling.',\n",
       "   'Systematic discrepancies in predicting Doppler width in the photosphere (w_p) for Ca II lines in quiet regions due to training data bias.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The DNN model achieves a 250-fold speedup in spectral inversion compared to traditional MLSI, enabling rapid analysis of large datasets.',\n",
       "    'The model accurately reproduces physical parameters and temporal variations, maintaining high correlation with MLSI results.',\n",
       "    'Innovative use of skip connections and multi-branch architecture enhances model performance and mitigates vanishing gradient issues.',\n",
       "    \"The model's high computational efficiency facilitates real-time or near-real-time analysis of solar observations.\",\n",
       "    'Potential for broad application to other observations or simulations of Hα and Ca II lines with similar wavelength ranges.'],\n",
       "   'weaknesses': ['Dependence on the quality of MLSI fits; the DNN may not perform well on spectra that MLSI cannot fit accurately.',\n",
       "    'Training data bias towards active regions may reduce reliability for quiet regions or limb observations.',\n",
       "    'Limited ability to handle atypical profiles, such as those from flares or fast-moving plasma, without additional sophisticated modeling.',\n",
       "    'Systematic errors in predicting certain parameters (e.g., Doppler width in quiet regions) due to biases in the training data.']},\n",
       "  'reuse_potential': ['The DNN model can be applied to large datasets from FISS and potentially other instruments with similar spectral observations.',\n",
       "   \"The model's efficiency allows for rapid generation of physical parameter maps, aiding in the study of chromospheric dynamics and heating mechanisms.\",\n",
       "   'The methodology can be extended to other spectral lines or adapted for use with different solar observation instruments.',\n",
       "   'Integration with existing solar data analysis pipelines, such as FISSPy, enhances accessibility and usability for the solar physics community.']},\n",
       " {'title': 'Examining the Source Regions of Solar Energetic Particles Using an AI-generated Synchronic Potential Field Source Surface Model',\n",
       "  'author': 'Park et al.',\n",
       "  'id': '10.3847/1538-4357/ace03d',\n",
       "  'data': ['AI-generated farside magnetograms (Jeong et al. 2022)',\n",
       "   'HMI magnetograms',\n",
       "   'GONG synoptic magnetograms',\n",
       "   'ADAPT synchronic magnetograms',\n",
       "   'STEREO/EUVI and SDO/AIA EUV images',\n",
       "   'GOES, STEREO, SOHO, ACE, and WIND spacecraft data'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['pfsspy'],\n",
       "  'task': 'Analysis of solar energetic particle (SEP) source regions using AI-generated magnetograms and PFSS extrapolations',\n",
       "  'abstract': 'The study investigates the source regions of six solar energetic particle (SEP) events accelerated near or behind the solar limbs using AI-generated farside magnetograms and Potential Field Source Surface (PFSS) extrapolations. The AI-generated magnetograms, combined with HMI data, provide near real-time farside magnetic field information, improving the understanding of SEP source regions. The research compares AI-generated magnetograms with conventional HMI, GONG, and ADAPT magnetograms, highlighting differences in magnetic field configurations and polarity inversion lines (PILs). Key findings include the emergence of new active regions (ARs) in AI-generated data, variations in magnetic flux, and more realistic EUV wave propagation patterns in AI-generated PFSS extrapolations. The study demonstrates the potential of AI-generated synchronic magnetograms for enhancing space weather forecasting.',\n",
       "  'models': ['Pix2PixHD (for AI-generated magnetograms)',\n",
       "   'PFSS (Potential Field Source Surface model)'],\n",
       "  'hybrid_model': True,\n",
       "  'multimodal': ['EUV images and magnetograms'],\n",
       "  'baselines': ['HMI-PFSS', 'GONG-PFSS', 'ADAPT-PFSS'],\n",
       "  'approach_used': ['Comparison of AI-generated and conventional magnetograms',\n",
       "   'PFSS extrapolation for magnetic field analysis',\n",
       "   'EUV wave propagation analysis'],\n",
       "  'methodology': 'The study uses AI-generated farside magnetograms combined with HMI data to create synchronic magnetograms, which are then used as input for PFSS extrapolations up to 2.5 solar radii. These extrapolations are compared with conventional HMI, GONG, and ADAPT magnetograms to analyze differences in magnetic field configurations, particularly focusing on SEP source regions. The analysis includes examining the emergence of new active regions (ARs), changes in magnetic flux, and the alignment of EUV wave propagation with polarity inversion lines (PILs).',\n",
       "  'metrics': ['Total unsigned magnetic flux',\n",
       "   'Polarity inversion line (PIL) configurations',\n",
       "   'EUV wave propagation patterns'],\n",
       "  'limitations': ['Uncertainties in determining the source surface magnetic footpoints of spacecraft',\n",
       "   'Potential inaccuracies in AI-generated magnetograms for newly emerging active regions',\n",
       "   'Limited temporal resolution for capturing rapid changes in magnetic fields'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Incorporation of near real-time farside magnetic field data using AI-generated magnetograms.',\n",
       "    'Improved understanding of SEP source regions and magnetic field connections.',\n",
       "    'More realistic EUV wave propagation patterns in AI-generated PFSS extrapolations.',\n",
       "    'Detection of newly emerging active regions not visible in conventional magnetograms.'],\n",
       "   'weaknesses': ['Dependence on the accuracy of AI-generated magnetograms, which may not capture all rapid changes in magnetic fields.',\n",
       "    'Uncertainties in the Parker spiral approximation for determining magnetic footpoints.',\n",
       "    'Limited to six SEP events, which may not represent all possible scenarios.']},\n",
       "  'reuse_potential': ['The AI-generated magnetograms and PFSS extrapolations can be reused for further studies on space weather forecasting.',\n",
       "   'The methodology can be applied to other solar events to improve the understanding of magnetic field configurations.',\n",
       "   'Potential integration with other solar observation tools to enhance real-time space weather monitoring.']},\n",
       " {'title': 'Forecast of Major Solar X-Ray Flare Flux Profiles Using Novel Deep Learning Models',\n",
       "  'author': 'Yi (Moon) et al.',\n",
       "  'id': '10.3847/2041-8213/ab747c',\n",
       "  'data': ['Geostationary Operational Environmental Satellite (GOES) 10 X-ray flux data from 1998 August to 2006 April'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'NumPy',\n",
       "   'scikit-learn',\n",
       "   'Pmdarima',\n",
       "   'Matplotlib'],\n",
       "  'task': 'Solar X-ray flare flux profile forecasting',\n",
       "  'abstract': 'The paper presents novel deep learning models for forecasting major solar X-ray flare flux profiles using a sequence-to-sequence (seq2seq) framework with Long Short-Term Memory (LSTM) and an attention mechanism. The models predict 30 minutes of X-ray flux profiles during the rise phase of solar flares with a one-minute time cadence. The study uses GOES X-ray flux data from 1998 to 2006, with 760 events for training and 85 for testing. The models are evaluated using 10-fold cross-validation and root mean square error (RMSE) metrics. Key findings include successful application of deep learning models without feature extraction, superior performance compared to other models, better performance for low-peak flux predictions, and accurate flare duration predictions.',\n",
       "  'models': ['LSTM', 'Sequence-to-Sequence (seq2seq)', 'Attention Mechanism'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Sequence-to-sequence learning',\n",
       "   'Attention mechanism',\n",
       "   'Time-series forecasting'],\n",
       "  'methodology': 'The study uses a dataset of 845 major solar flare events from GOES 10 X-ray flux data. The data is split into training (90%) and testing (10%) sets, with 10-fold cross-validation to ensure robustness. The proposed models are based on the seq2seq framework with LSTM and an attention mechanism. The models are evaluated using RMSE metrics for all forecasting results, peak flux, and different forecast start times. Comparisons are made with conventional regression models (ARIMA, KNNR, SVMR, RFR) and simpler deep learning models (MLP, Simple-LSTM).',\n",
       "  'metrics': ['Root Mean Square Error (RMSE) for all forecasting results',\n",
       "   'RMSE for peak flux',\n",
       "   'RMSE for different forecast start times'],\n",
       "  'limitations': ['The model performs better for weaker flares compared to stronger flares, potentially due to class imbalance and the dynamic nature of stronger flares.',\n",
       "   'The assumption of a Poisson distribution for flare events may not fully capture the temporal distribution of flares.',\n",
       "   'The dataset is limited to GOES 10 X-ray flux data from 1998 to 2006, which may not represent the full range of solar flare behaviors.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Novel use of seq2seq and attention mechanisms for solar flare forecasting.',\n",
       "    'No need for feature extraction preprocessing.',\n",
       "    'High accuracy in predicting flare duration and low-peak flux profiles.',\n",
       "    'Superior performance compared to conventional regression and simpler deep learning models.'],\n",
       "   'weaknesses': ['Performance disparity between weaker and stronger flares.',\n",
       "    'Dependence on the assumption of flare event distribution.',\n",
       "    'Limited dataset scope and time range.']},\n",
       "  'reuse_potential': ['The methodology can be applied to other time-series forecasting tasks in astronomy and space weather.',\n",
       "   'Potential for use in predicting ionospheric behavior and other solar-related phenomena.',\n",
       "   'The models can be adapted for other scientific fields requiring time-series predictions.']},\n",
       " {'title': 'Comparison of Empirical and Deep Learning Models for Solar Wind Speed Prediction',\n",
       "  'author': 'Ahn et al.',\n",
       "  'id': '10.3847/1538-4357/ad4b3a',\n",
       "  'data': ['SDO/AIA EUV images (211Å and 193Å)',\n",
       "   'OMNI solar wind speed data',\n",
       "   'GONG synoptic maps',\n",
       "   'Richardson and Cane ICME catalog'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['TensorFlow/PyTorch (implied, not explicitly stated)'],\n",
       "  'task': 'Solar wind speed prediction',\n",
       "  'abstract': 'The study compares empirical models (WSA-ENLIL and ESWF 3.2) with a deep learning model for predicting solar wind speed at 1 astronomical unit (au). The deep learning model uses extreme-ultraviolet (EUV) images and historical solar wind speed data to forecast solar wind speed up to 3 days ahead. Evaluation over the period 2012-2020 shows that the deep learning model outperforms empirical models in terms of mean absolute error (MAE), root mean square error (RMSE), and correlation coefficient (CC). It particularly excels during high-speed solar wind streams (HSS) event predictions, achieving a high success ratio (SR) of 0.82 and minimizing false alarms.',\n",
       "  'models': ['Convolutional Neural Network (CNN) with Inception blocks',\n",
       "   'Long Short-Term Memory (LSTM)',\n",
       "   'Dense layers'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['EUV images', 'Historical solar wind speed data'],\n",
       "  'baselines': ['WSA-ENLIL model',\n",
       "   'ESWF 3.2 model',\n",
       "   'Persistence models (3, 4, 5, and 27 days)'],\n",
       "  'approach_used': ['Statistical verification (MAE, RMSE, CC)',\n",
       "   'Event-based verification (POD, FNR, SR, FAR, CSI, BS)'],\n",
       "  'methodology': 'The study evaluates the performance of a deep learning model against empirical models (WSA-ENLIL and ESWF 3.2) for solar wind speed prediction. The deep learning model uses EUV images (211Å and 193Å) and up to 5 days of historical solar wind speed data to predict solar wind speed up to 3 days ahead. The models are tested over the period 2012-2020, excluding interplanetary coronal mass ejection (ICME) periods. Statistical verification includes metrics like MAE, RMSE, and CC, while event-based verification focuses on detecting high-speed solar wind streams (HSS) events using metrics such as POD, FNR, SR, FAR, CSI, and BS. The deep learning model demonstrates superior performance in both statistical and event-based evaluations.',\n",
       "  'metrics': ['Mean Absolute Error (MAE)',\n",
       "   'Root Mean Square Error (RMSE)',\n",
       "   'Correlation Coefficient (CC)',\n",
       "   'Probability of Detection (POD)',\n",
       "   'False Negative Rate (FNR)',\n",
       "   'Success Ratio (SR)',\n",
       "   'False Alarm Ratio (FAR)',\n",
       "   'Critical Success Index (CSI)',\n",
       "   'Bias Score (BS)'],\n",
       "  'limitations': ['The deep learning model tends to underestimate the frequency of high-speed solar wind events.',\n",
       "   'Performance drops during the solar maximum phase due to inadequate learning of magnetic field structures.',\n",
       "   'Limited incorporation of coronal mass ejection (CME) data.',\n",
       "   'Potential over-reliance on coronal hole (CH) areas for predictions.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The deep learning model outperforms empirical models in both statistical and event-based evaluations.',\n",
       "    'Achieves a high success ratio (SR) of 0.82, minimizing false alarms.',\n",
       "    'Provides near-real-time predictions with an inference time of less than a minute.',\n",
       "    'Effectively captures coronal hole areas for accurate predictions during descending and minimum solar activity phases.'],\n",
       "   'weaknesses': ['Struggles to predict solar wind speed during the solar maximum phase.',\n",
       "    'Tends to underestimate the occurrence of high-speed solar wind events.',\n",
       "    'Limited ability to incorporate dynamic variability of solar wind speed.',\n",
       "    'Lacks comprehensive integration of CME data, affecting prediction accuracy during eruptive events.']},\n",
       "  'reuse_potential': ['The deep learning model can be integrated into space weather forecasting systems for improved solar wind speed predictions.',\n",
       "   'Potential to enhance the model by incorporating magnetogram data or squashing factors to better capture magnetic field structures.',\n",
       "   'Future work could explore hybrid models combining deep learning with empirical methods for better event detection sensitivity.',\n",
       "   \"The model's architecture can be adapted for predicting other space weather phenomena.\"]},\n",
       " {'title': 'Pixel-to-pixel Translation of Solar Extreme-ultraviolet Images for DEMs by Fully Connected Networks',\n",
       "  'author': 'Park et al.',\n",
       "  'id': '10.3847/1538-4357/aca42a',\n",
       "  'data': ['SDO/AIA six-EUV-channel data (17.1, 19.3, 21.1, 9.4, 13.1, and 33.5 nm)'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['astropy', 'sunpy', 'aiapy', 'pytorch', 'numpy'],\n",
       "  'task': 'Pixel-to-pixel translation of solar EUV images for Differential Emission Measure (DEM) estimation',\n",
       "  'abstract': \"The study introduces a pixel-to-pixel image translation method for solar extreme-ultraviolet (EUV) images using a fully connected network (FCN) model. The model translates three input EUV channels (17.1, 19.3, and 21.1 nm) from the SDO/AIA instrument into three target channels (9.4, 13.1, and 33.5 nm). The FCN model assumes pixel independence, which is effective for EUV image translation and avoids boundary effects seen in convolutional neural network (CNN) models. The study evaluates the model's performance by comparing generated EUV images with actual SDO/AIA data and calculating Differential Emission Measures (DEMs). The results show that the FCN model generates EUV images with high correlation coefficients (0.78, 0.89, and 0.85 for the 9.4, 13.1, and 33.5 nm channels, respectively) and reduces noise significantly. The DEMs derived from the AI-generated images are consistent with those from SDO/AIA data, demonstrating the model's reliability and potential for scientific applications.\",\n",
       "  'models': ['Fully Connected Network (FCN)',\n",
       "   'Convolutional Neural Network (CNN)'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['CNN-based model'],\n",
       "  'approach_used': ['Pixel-to-pixel translation',\n",
       "   'Fully connected layers',\n",
       "   'Skip connections',\n",
       "   'L2 loss function',\n",
       "   'Adam optimizer'],\n",
       "  'methodology': \"The study uses SDO/AIA EUV images from six channels, with three channels (17.1, 19.3, and 21.1 nm) as input and the remaining three (9.4, 13.1, and 33.5 nm) as target data. The FCN model is designed with an encoder-decoder structure, including skip connections, and trained using the L2 loss function and the Adam optimizer. The model's performance is evaluated by comparing generated images with actual SDO/AIA data and calculating DEMs using the SITES DEM solver. The FCN model successfully generates EUV images with reduced noise and high correlation coefficients, and the DEMs derived from these images are consistent with those from SDO/AIA data.\",\n",
       "  'metrics': ['Correlation Coefficient (CC)',\n",
       "   'Root Mean Square Error (RMSE)',\n",
       "   'Signal-to-Noise Ratio (S/N)'],\n",
       "  'limitations': ['The FCN model assumes pixel independence, which may not be suitable for translating images between dissimilar domains (e.g., EUV images and magnetograms).',\n",
       "   \"The model's performance is dependent on the quality and noise level of input data.\",\n",
       "   \"The study does not explore the model's applicability to high-temperature transient phenomena like flares or jets.\"],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The FCN model effectively translates EUV images with high correlation coefficients and reduced noise.',\n",
       "    'The model avoids boundary effects seen in CNN models.',\n",
       "    'DEMs derived from AI-generated images are consistent with those from SDO/AIA data.',\n",
       "    'The model is computationally efficient and maintains high time cadence without stacking.'],\n",
       "   'weaknesses': [\"The assumption of pixel independence may limit the model's applicability to certain types of image translation.\",\n",
       "    \"The model's performance may degrade with noisy or low-quality input data.\",\n",
       "    'Further validation is needed for high-temperature transient phenomena.']},\n",
       "  'reuse_potential': ['The FCN model can be applied to other solar EUV datasets and potentially extended to other types of astronomical image translation tasks.',\n",
       "   'The methodology can be reused for selecting EUV channels in future small satellite missions.',\n",
       "   \"The model's noise reduction capability can be beneficial for scientific applications requiring high-quality images.\"]},\n",
       " {'title': 'Selection of Three (Extreme)Ultraviolet Channels for Solar Satellite Missions by Deep Learning',\n",
       "  'author': 'Lim et al.',\n",
       "  'id': '10.3847/2041-8213/ac0829',\n",
       "  'data': ['SDO/AIA observations in two UV channels (1600 and 1700 Å) and seven EUV channels (94, 131, 171, 193, 211, 304, and 335 Å) with 12 hr cadence from 2011 to 2017'],\n",
       "  'code_link': 'https://github.com/eunsu-park/solar_euv_generation',\n",
       "  'packages_used': ['NumPy', 'Keras', 'SolarSoftWare'],\n",
       "  'task': 'Channel selection for UV/EUV solar observations using deep learning-based image translation',\n",
       "  'abstract': 'The paper addresses the question of which combination of channels can best translate other channels in ultraviolet (UV) and extreme UV (EUV) solar observations. The study uses data from the nine channels of the Atmospheric Imaging Assembly (AIA) on board the Solar Dynamics Observatory (SDO) and develops 170 deep learning models: 72 models for single-channel input, 56 models for double-channel input, and 42 models for triple-channel input. The models are evaluated using pixel-to-pixel correlation coefficients (CCs) within the solar disk. Key findings include: (1) The model with 131 Å shows the best performance among single-channel models, (2) the model with 131 and 1600 Å shows the best translation among double-channel models, and (3) the model with 131, 1600, and 304 Å is suggested among triple-channel models due to its highest minimum CC. The results can be used as a secondary perspective in selecting channels for future solar satellite missions.',\n",
       "  'models': ['Conditional Generative Adversarial Networks (cGAN)', 'pix2pix'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['Multiple linear regression model'],\n",
       "  'approach_used': ['Image translation using deep learning',\n",
       "   'Quantitative evaluation using pixel-to-pixel correlation coefficients'],\n",
       "  'methodology': 'The study uses SDO/AIA data from nine channels, preprocessed and scaled to 1024x1024 images. The data is divided into training, validation, and test sets based on the solar cycle phase. The deep learning models are based on pix2pix, a conditional generative adversarial network (cGAN) architecture. The models are evaluated using pixel-to-pixel correlation coefficients (CCs) within the solar disk. The study compares the performance of single-, double-, and triple-channel input models, highlighting the best-performing combinations for translating other channels.',\n",
       "  'metrics': ['Pixel-to-pixel correlation coefficients (CCs)',\n",
       "   'Root Mean Square (RMS) errors',\n",
       "   'Joint Probability Density Function (JPDF)'],\n",
       "  'limitations': ['The study does not consider all possible input combinations, limiting the exploration of potentially better channel combinations.',\n",
       "   'The accuracy of the deep learning models may not be sufficient to fully replace real measurements, indicating a need for further improvement.',\n",
       "   'The use of scaled-down images (1024x1024) may result in information loss compared to the original 4096x4096 SDO/AIA images.',\n",
       "   'The dynamic range adjustment of the data may limit the quantitative study within the adjusted range.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The study provides a comprehensive comparison of 170 deep learning models for translating UV/EUV solar observations, offering valuable insights into optimal channel combinations.',\n",
       "    'The methodology is well-documented, including data preprocessing, model architecture, and evaluation metrics.',\n",
       "    'The use of pixel-to-pixel correlation coefficients (CCs) provides a clear and quantitative measure of model performance.',\n",
       "    'The inclusion of both full-disk and localized region comparisons (e.g., coronal holes and active regions) enhances the robustness of the findings.',\n",
       "    'The study offers practical recommendations for selecting channels in future solar satellite missions, balancing scientific and technical considerations.'],\n",
       "   'weaknesses': ['The study does not explore all possible combinations of input channels, which could potentially yield better-performing models.',\n",
       "    \"The deep learning models' accuracy may not be sufficient for fully replacing real measurements, as indicated by the quantitative comparison with the base model.\",\n",
       "    'The use of scaled-down images (1024x1024) may result in some loss of information compared to the original high-resolution SDO/AIA images.',\n",
       "    'The dynamic range adjustment limits the applicability of the model outputs for quantitative studies outside the adjusted range.',\n",
       "    'The computational resources and time required to train and evaluate 170 models may be prohibitive for some researchers.']}},\n",
       " {'title': 'De-noising SDO/HMI Solar Magnetograms by Image Translation Method Based on Deep Learning',\n",
       "  'author': 'Park et al.',\n",
       "  'id': '10.3847/2041-8213/ab775c',\n",
       "  'data': ['Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI) line-of-sight magnetograms'],\n",
       "  'code_link': 'https://github.com/eunsu-park/solar_magnetogram_denoising',\n",
       "  'packages_used': ['NumPy', 'Keras', 'TensorFlow', 'SunPy'],\n",
       "  'task': 'De-noising solar magnetograms',\n",
       "  'abstract': 'The paper applies a deep-learning model based on a deep convolutional generative adversarial network (DCGAN) to de-noise solar magnetograms. The model translates single-frame magnetograms into stacked (21-frame) magnetograms, significantly reducing noise levels. The average noise level was reduced from 8.66 G to 3.21 G, matching the noise level of the target stacked magnetograms. The de-noised magnetograms showed improved consistency with the target ones, with the pixel-to-pixel correlation coefficient increasing from 0.88 to 0.94. This method has potential applications in various scientific fields where long-exposure observations are used to improve signal-to-noise ratios.',\n",
       "  'models': ['Deep Convolutional Generative Adversarial Network (DCGAN)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Image-to-image translation using DCGAN'],\n",
       "  'methodology': 'The study uses a DCGAN model to translate single-frame SDO/HMI magnetograms into stacked (21-frame) magnetograms, which have lower noise levels. The model consists of a generator that creates de-noised magnetograms and a discriminator that distinguishes between real (stacked) and fake (de-noised) magnetograms. The training process involves minimizing L1 loss and conditional GAN (cGAN) loss. The model was trained on 7004 pairs of magnetograms, validated on 707 pairs, and tested on 736 pairs. The de-noised magnetograms were evaluated using metrics such as noise levels, pixel-to-pixel correlation, relative error of total unsigned magnetic flux, linear fitting of total unsigned magnetic flux, normalized mean squared error, and peak signal-to-noise ratio.',\n",
       "  'metrics': ['Noise level (Gaussian fitting to histogram of magnetic flux densities)',\n",
       "   'Pixel-to-pixel correlation coefficient',\n",
       "   'Relative error (RE) of total unsigned magnetic flux (TUMF)',\n",
       "   'Linear fitting of TUMF',\n",
       "   'Normalized mean squared error (NMSE)',\n",
       "   'Peak signal-to-noise ratio (S/N)'],\n",
       "  'limitations': ['The model is trained on data from a specific region (center of the solar disk), which may limit its generalizability to other regions or different types of solar data.',\n",
       "   'The effectiveness of the model depends on the quality and representativeness of the training data.',\n",
       "   'The method assumes minimal significant motion of features during the integration of frames, which may not always be the case.',\n",
       "   'The computational resources required for training and applying the model may be substantial.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The model successfully reduces noise levels in solar magnetograms, achieving an average noise level comparable to that of the target stacked magnetograms.',\n",
       "    'The de-noised magnetograms show high consistency with the target magnetograms, as evidenced by the increased pixel-to-pixel correlation coefficient.',\n",
       "    'The approach leverages deep learning techniques, specifically DCGAN, which is well-suited for image-to-image translation tasks.',\n",
       "    'The methodology is well-documented, and the code is publicly available, enhancing transparency and reproducibility.',\n",
       "    'Potential applications extend beyond solar magnetograms to other fields where improving signal-to-noise ratios is crucial.'],\n",
       "   'weaknesses': [\"The model's performance may vary when applied to regions outside the center of the solar disk or to different types of solar data.\",\n",
       "    'The reliance on high-quality training data could be a limitation in scenarios where such data is scarce or not representative.',\n",
       "    \"The assumption of minimal feature motion during frame integration may not hold in all cases, potentially affecting the model's accuracy.\",\n",
       "    'The computational cost of training and applying the model could be a barrier for some users.']},\n",
       "  'reuse_potential': ['The model and methodology can be adapted for de-noising tasks in other astronomical observations where long-exposure or stacked images are used.',\n",
       "   'The approach can potentially be applied to medical imaging, satellite imagery, and other fields requiring noise reduction in visual data.',\n",
       "   'The publicly available code allows other researchers to build on or adapt the model for their specific needs.']},\n",
       " {'title': 'Super-resolution of SDO/HMI Magnetograms Using Novel Deep Learning Methods',\n",
       "  'author': 'Rahman et al.',\n",
       "  'id': '10.3847/2041-8213/ab9d3d',\n",
       "  'data': ['SDO/HMI LOS magnetograms (2014-2015)',\n",
       "   'Hinode/SOT NFI magnetograms (2013)'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['SunPy', 'PyTorch', 'TensorFlow', 'SolarSoft'],\n",
       "  'task': 'Super-resolution of solar magnetograms',\n",
       "  'abstract': 'The paper applies two deep learning models (residual attention model and progressive GAN) to enhance the resolution of SDO/HMI magnetograms. The models are trained on degraded low-resolution (LR) magnetograms and their corresponding high-resolution (HR) counterparts. The study demonstrates that deep learning models outperform traditional bicubic interpolation in terms of visual quality and quantitative metrics such as peak signal-to-noise ratio (S/N), correlation coefficient (CC), root mean square error (RMSE), and structural similarity index (SSIM). The generated super-resolved magnetograms are also compared with Hinode/SOT NFI magnetograms, showing high consistency (CC: 0.94, SSIM: 0.93).',\n",
       "  'models': ['Residual Attention Model', 'Progressive GAN'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['Bicubic interpolation'],\n",
       "  'approach_used': ['Deep learning-based super-resolution',\n",
       "   'Residual learning',\n",
       "   'Attention mechanisms',\n",
       "   'Progressive multi-scale GAN'],\n",
       "  'methodology': 'The study uses two deep learning models: the residual attention model and the progressive GAN model. The residual attention model employs a deep residual network with channel-wise attention mechanisms to focus on informative features, while the progressive GAN model uses a multi-scale approach to enhance perceptual quality. Both models are trained on pairs of degraded LR and HR SDO/HMI magnetograms. The performance is evaluated using metrics such as peak S/N, CC, RMSE, and SSIM, and the results are compared with bicubic interpolation. The models are also validated by comparing the generated magnetograms with Hinode/SOT NFI magnetograms.',\n",
       "  'metrics': ['Peak signal-to-noise ratio (S/N)',\n",
       "   \"Pixel-to-pixel Pearson's correlation coefficient (CC)\",\n",
       "   'Root mean square error (RMSE)',\n",
       "   'Structural similarity index (SSIM)'],\n",
       "  'limitations': ['The study notes that super-resolution is an ill-defined problem for solar magnetograms, and while deep learning models improve resolution, they may not capture all small-scale features perfectly.',\n",
       "   'The performance of the models decreases significantly for larger scaling factors (e.g., 8×8 binning).',\n",
       "   'The study relies on synthetic degradation of HR images to create LR inputs, which may not fully represent real-world degradation processes.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['The paper demonstrates significant improvements in super-resolution quality over traditional methods like bicubic interpolation.',\n",
       "    'The use of attention mechanisms in the residual attention model enhances feature learning and improves the reconstruction of small-scale magnetic structures.',\n",
       "    'The progressive GAN model effectively enhances perceptual quality through multi-scale upsampling.',\n",
       "    'The study includes a thorough comparison with Hinode/SOT NFI magnetograms, validating the consistency and accuracy of the generated images.'],\n",
       "   'weaknesses': ['The reliance on synthetic degradation for creating LR inputs may limit the generalizability of the results to real-world scenarios.',\n",
       "    'The models struggle with larger scaling factors, indicating limitations in handling extreme super-resolution tasks.',\n",
       "    'The study does not explore the potential of combining multiple modalities (e.g., magnetograms with other solar observations) to further improve super-resolution performance.']},\n",
       "  'reuse_potential': ['The methodology and models presented in this paper can be applied to other astronomical images beyond solar magnetograms, such as images from different telescopes or wavelengths.',\n",
       "   'The attention mechanisms and progressive GAN techniques can be adapted for other image super-resolution tasks in different domains.',\n",
       "   'The open-source tools and libraries used (e.g., SunPy, PyTorch) facilitate reproducibility and further experimentation by the community.']},\n",
       " {'title': 'Generation of Solar Coronal White-light Images from SDO/AIA EUV Images by Deep Learning',\n",
       "  'author': 'Lawrance et al.',\n",
       "  'id': '10.3847/1538-4357/ac8d81',\n",
       "  'data': ['SDO/AIA EUV images (171, 193, and 211 Å)',\n",
       "   'MLSO K-Cor white-light images'],\n",
       "  'code_link': 'None provided',\n",
       "  'packages_used': ['Numpy', 'Keras', 'TensorFlow', 'SunPy', 'SolarSoftware'],\n",
       "  'task': 'Generation of MLSO K-Cor-like white-light images from SDO/AIA EUV images',\n",
       "  'abstract': 'The paper presents a deep learning model based on conditional generative adversarial networks (cGANs) to generate Mauna Loa Solar Observatory (MLSO) K-coronagraph-like white-light images from Solar Dynamics Observatory/Atmospheric Imaging Assembly (SDO/AIA) EUV images. The study used pairs of SDO/AIA EUV images and corresponding MLSO K-coronagraph images from 2014 to 2019 to train the model. Seven models were created, with the best model using AIA 193 and 211 Å channels, achieving a correlation coefficient of 0.938. The AI-generated images successfully identified low coronal features such as helmet streamers, pseudostreamers, and polar coronal holes, as well as solar eruptions like coronal mass ejections (CMEs) and jets. The model aims to provide complementary data for studying low coronal features, especially during nonobservable cases.',\n",
       "  'models': ['Conditional Generative Adversarial Networks (cGANs)', 'Pix2Pix'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': ['N/A'],\n",
       "  'baselines': ['N/A'],\n",
       "  'approach_used': ['Image-to-image translation using cGANs',\n",
       "   'Data preprocessing including polar coordinate transformation and log scaling'],\n",
       "  'methodology': 'The study utilized a pix2pix model based on cGANs to generate white-light images from SDO/AIA EUV images. The model was trained on 21,071 pairs of images from 2013 to 2019, with data split into training, testing, and validation sets. The best model was selected based on the highest mean correlation coefficient (CC) value. The AI-generated images were evaluated by comparing them with target white-light images, focusing on features like helmet streamers, pseudostreamers, and polar coronal holes. The model was also tested on its ability to generate solar eruptions like CMEs and jets.',\n",
       "  'metrics': ['Correlation Coefficient (CC)',\n",
       "   'Normalized Root Mean Square Error (NRMSE)'],\n",
       "  'limitations': ['The model struggles with generating faint CMEs.',\n",
       "   'Dependence on the quality and availability of SDO/AIA and MLSO K-Cor images.',\n",
       "   'Potential inaccuracies in the generated images during complex solar events.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Successful generation of white-light images with high correlation to target images.',\n",
       "    'Ability to identify and reproduce major low coronal features and solar eruptions.',\n",
       "    'Potential to fill data gaps during nonobservable periods.'],\n",
       "   'weaknesses': ['Difficulty in accurately generating faint CMEs.',\n",
       "    'Requires high-quality input data for optimal performance.',\n",
       "    'Limited by the field of view and resolution of input images.']},\n",
       "  'reuse_potential': ['The model can be reused to generate white-light images for periods when MLSO K-Cor data is unavailable.',\n",
       "   'Potential application in space weather forecasting by providing continuous monitoring of solar eruptions.',\n",
       "   'Can be extended to generate other types of solar images or data products using similar deep learning approaches.']},\n",
       " {'title': 'Solar Coronal Magnetic Field Extrapolation from Synchronic Data with AI-generated Farside',\n",
       "  'author': 'Jeong et al.',\n",
       "  'id': '10.3847/2041-8213/abc59b',\n",
       "  'data': ['SDO/AIA three passband images (304, 193, and 171 Å)',\n",
       "   'SDO/HMI LOS 720 s magnetograms',\n",
       "   'STEREO/EUVI A and B (304, 195, and 171 Å) passband images'],\n",
       "  'code_link': 'https://github.com/JeongHyunJin/Jeong2020_SolarFarsideMagnetograms',\n",
       "  'packages_used': ['SolarSoftWare (SSW)',\n",
       "   'PyTorch (implied by deep learning implementation)'],\n",
       "  'task': 'Solar farside magnetogram generation and coronal magnetic field extrapolation',\n",
       "  'abstract': 'The paper introduces a novel method for generating near-real-time AI-based farside magnetograms of the Sun using deep learning. The generated magnetograms are used to create synchronic maps of the solar magnetic field, which are then utilized in the Potential Field Source Surface (PFSS) model to extrapolate the global coronal magnetic fields. The results are more consistent with coronal observations compared to conventional methods, offering significant improvements in the study of solar corona, heliosphere, and space weather.',\n",
       "  'models': ['Pix2PixHD'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Deep learning-based image translation',\n",
       "   'Pix2PixHD for generating farside magnetograms',\n",
       "   'PFSS model for coronal magnetic field extrapolation'],\n",
       "  'methodology': 'The methodology involves training a Pix2PixHD model using SDO/AIA EUV images and SDO/HMI magnetograms to generate farside magnetograms. These generated magnetograms are then used to create synchronic maps of the solar magnetic field. The PFSS model is used to extrapolate the coronal magnetic fields from these synchronic maps. The results are validated by comparing them with EUV observations.',\n",
       "  'metrics': ['Correlation Coefficients (CCs)',\n",
       "   'Total Unsigned Magnetic Flux (TUMF)',\n",
       "   'Net Magnetic Flux (NMF)',\n",
       "   'Pixel-to-pixel CCs'],\n",
       "  'limitations': ['Dependence on the quality of STEREO and SDO data',\n",
       "   'Limited to the dynamic range of ±3000 Gauss',\n",
       "   'Potential inaccuracies in AI-generated magnetograms for rapidly changing magnetic fields'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Improved accuracy in generating farside magnetograms compared to previous models.',\n",
       "    'Enhanced consistency of coronal magnetic field extrapolations with EUV observations.',\n",
       "    'Near-real-time capability for monitoring solar magnetic fields.',\n",
       "    'Potential for integration with other models like MAS for better heliospheric predictions.'],\n",
       "   'weaknesses': ['Dependence on high-quality input data from STEREO and SDO.',\n",
       "    'Challenges in capturing rapid changes in magnetic fields.',\n",
       "    'Limited dynamic range for magnetic field strength.']},\n",
       "  'reuse_potential': ['Integration with other solar observation models for improved space weather forecasting.',\n",
       "   'Potential application in studying long-term solar magnetic flux evolution.',\n",
       "   'Use in heliospheric and space weather prediction models like WSA and ENLIL.']},\n",
       " {'title': 'Generation of Solar UV and EUV Images from SDO/HMI Magnetograms by Deep Learning',\n",
       "  'author': 'Park et al.',\n",
       "  'id': '10.3847/2041-8213/ab493a',\n",
       "  'data': ['SDO/HMI line-of-sight (LOS) magnetograms',\n",
       "   'SDO/AIA nine-passband (94, 131, 171, 193, 211, 304, 335, 1600, and 1700 Å) UV/EUV images'],\n",
       "  'code_link': 'https://github.com/eunsu-park/solar_euv_generation',\n",
       "  'packages_used': ['NumPy', 'Keras', 'TensorFlow', 'SunPy', 'SolarSoft'],\n",
       "  'task': 'Image-to-image translation from solar magnetograms to solar UV and EUV images',\n",
       "  'abstract': 'The paper applies deep learning methods to translate solar magnetograms into solar ultraviolet (UV) and extreme ultraviolet (EUV) images. Two convolutional neural network (CNN) models were used: one with L1 loss (Model A) and another with L1 and conditional generative adversarial network (cGAN) loss (Model B). The models were trained on pairs of SDO/AIA UV/EUV images and SDO/HMI magnetograms from 2011 to 2016 and evaluated on data from 2017. Model A generally performed slightly better in terms of pixel-to-pixel correlation, relative error, and percentage of pixels with errors less than 10%, while Model B produced less blurred images due to the cGAN loss.',\n",
       "  'models': ['CNN with L1 loss', 'CNN with L1 and cGAN loss'],\n",
       "  'hybrid_model': False,\n",
       "  'multimodal': [],\n",
       "  'baselines': ['Comparison of Model A (L1 loss) and Model B (L1 + cGAN loss)'],\n",
       "  'approach_used': ['Image-to-image translation using CNNs',\n",
       "   'Use of L1 loss and cGAN loss for generating realistic images'],\n",
       "  'methodology': 'The study involved training two CNN models: Model A with L1 loss and Model B with L1 and cGAN loss. The models were trained on pairs of SDO/AIA UV/EUV images and SDO/HMI magnetograms. The training data included images from 2011 to 2016, with validation and testing performed on data from 2017. The performance of the models was evaluated using metrics such as pixel-to-pixel correlation coefficient, relative error, and the percentage of pixels with errors less than 10%. Model A generally showed better performance in these metrics, but Model B produced less blurred images due to the inclusion of cGAN loss.',\n",
       "  'metrics': ['Pixel-to-pixel correlation coefficient',\n",
       "   'Relative error',\n",
       "   'Percentage of pixels with errors less than 10%',\n",
       "   'Root mean square contrast measure (CM)'],\n",
       "  'limitations': ['The models were trained and tested on chronologically separated datasets, which may not fully account for solar cycle phase effects and time-varied instrument degradation.',\n",
       "   'The generated images, especially for complex structures like coronal loops and active regions, may lack fine details compared to real observations.',\n",
       "   'The study did not explore other advanced architectures or multimodal approaches that could potentially improve performance.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Successful generation of SDO/AIA-like solar UV and EUV images from SDO/HMI magnetograms.',\n",
       "    'Quantitative evaluation using multiple metrics shows the effectiveness of the models.',\n",
       "    'Model B with cGAN loss produces less blurred images, indicating better realism.',\n",
       "    'Open-source code and detailed methodology provided for reproducibility.'],\n",
       "   'weaknesses': ['The models may struggle with generating fine details in complex solar structures.',\n",
       "    'Chronological data splitting might not fully capture solar cycle variations.',\n",
       "    'No exploration of hybrid or multimodal models that could potentially enhance performance.']},\n",
       "  'reuse_potential': ['The methodology can be extended to other multiwavelength image translation tasks in astronomy and beyond.',\n",
       "   'Potential for improving space weather forecasting by generating UV/EUV images from historical magnetogram data.',\n",
       "   'The models and code can be adapted for educational purposes or further research in solar image analysis.']},\n",
       " {'title': 'Prediction of the Next Solar Rotation Synoptic Maps Using an Artificial Intelligence-based Surface Flux Transport Model',\n",
       "  'author': 'Jeong (Hyun-Jin) et al.',\n",
       "  'id': '10.3847/1538-4357/ad3416',\n",
       "  'data': ['Solar Dynamics Observatory/Helioseismic and Magnetic Imager (SDO/HMI) synoptic maps (2010–2023)',\n",
       "   'Solar and Heliospheric Observatory/Michelson Doppler Imager (SOHO/MDI) synoptic maps (1996–2010)',\n",
       "   'National Solar Observatory/Global Oscillation Network Group (NSO/GONG) synoptic maps (2006–2023)'],\n",
       "  'code_link': 'https://github.com/antyeates1983/sft_data',\n",
       "  'packages_used': ['PyTorch',\n",
       "   'SunPy',\n",
       "   'Astropy',\n",
       "   'SciPy',\n",
       "   'NumPy',\n",
       "   'Matplotlib',\n",
       "   'Scikit-image'],\n",
       "  'task': 'Prediction of solar synoptic maps for the next solar rotation (27.2753 days)',\n",
       "  'abstract': 'The study introduces an AI-based Surface Flux Transport (SFT) model to predict solar synoptic maps for the next solar rotation using deep learning. The model leverages the Pix2PixCC architecture and is trained on synoptic maps from SDO/HMI, SOHO/MDI, and NSO/GONG spanning 1996–2023. The AI-generated maps are compared with results from the persistent model and the conventional SFT model, showing improved performance in terms of correlation coefficients and feature similarity. The model successfully captures magnetic features like active region diffusion and supergranule motions, and synthetic data tests confirm its ability to reproduce differential rotation and meridional flow.',\n",
       "  'models': ['Pix2PixCC (modified with U-Net generator)'],\n",
       "  'hybrid_model': False,\n",
       "  'approach_used': ['Deep learning-based image-to-image translation',\n",
       "   'Data augmentation via longitudinal shifting',\n",
       "   'K-fold cross-validation (K=6)'],\n",
       "  'methodology': \"The study employs a deep-learning model based on the Pix2PixCC architecture, incorporating a U-Net generator, discriminator, and inspector. The model is trained on synoptic maps with a resolution of 360x180 (longitude and sine latitude) and uses objective functions including least-squares GAN loss, feature-matching loss, and correlation coefficient loss. Data augmentation is applied by shifting the maps longitudinally to enhance training diversity. The model's performance is evaluated using metrics such as RMSE, FSIM, and pixel-to-pixel correlation coefficients, and it is compared against the conventional SFT model and a persistent model.\",\n",
       "  'metrics': ['Root Mean Square Error (RMSE)',\n",
       "   'Feature Similarity Index Measure (FSIM)',\n",
       "   'Pixel-to-pixel Pearson Correlation Coefficient (CC)'],\n",
       "  'limitations': ['Inability to predict newly emerging active regions during a solar rotation.',\n",
       "   'Dependence on historical data for training, limiting predictions to patterns seen in past solar cycles.',\n",
       "   'Challenges in capturing extreme space weather events due to the lack of emerging flux prediction.'],\n",
       "  'reproducibility': 4,\n",
       "  'key_points': {'strengths': ['Improved prediction accuracy over conventional SFT and persistent models.',\n",
       "    'Successful implementation of differential rotation and meridional flow using synthetic data.',\n",
       "    'Iterative forecasting capability for multiple solar rotations.',\n",
       "    'Effective use of data augmentation to handle limited training data.'],\n",
       "   'weaknesses': ['Limited ability to predict newly emerging active regions.',\n",
       "    'Dependence on historical data may restrict adaptability to unprecedented solar events.',\n",
       "    'Potential challenges in generalizing to extreme space weather conditions.']},\n",
       "  'reuse_potential': ['Potential for integration with solar coronal and heliospheric models to enhance space weather forecasting.',\n",
       "   'Applicability in estimating empirical profiles from 2D observations using synthetic data.',\n",
       "   'Use in predicting solar activity cycles and global coronal structures.']}]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14473d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
